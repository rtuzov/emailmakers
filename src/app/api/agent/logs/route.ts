import { NextRequest, NextResponse } from 'next/server';
import { logger } from '@/agent/core/logger';
import fs from 'fs/promises';
import fsSync from 'fs';
import path from 'path';

interface LogEntry {
  level: 'debug' | 'info' | 'warn' | 'error';
  msg: string;
  timestamp: string;
  tool?: string;
  error?: string;
  duration?: number;
  requestId?: string;
  userId?: string;
}

/**
 * GET /api/agent/logs
 * –ü–æ–ª—É—á–∏—Ç—å –ª–æ–≥–∏ —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞ –∏ trace –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
 */
export async function GET(request: NextRequest) {
  try {
    const { searchParams } = new URL(request.url);
    const level = searchParams.get('level') || 'info'; // debug, info, warn, error
    const limit = parseInt(searchParams.get('limit') || '100');
    const since = searchParams.get('since'); // ISO timestamp
    const tool = searchParams.get('tool'); // filter by specific tool
    const format = searchParams.get('format') || 'json'; // json, text, prometheus

    console.log('üîç Agent logs request:', { level, limit, since, tool, format });

    // Handle Prometheus metrics format
    if (format === 'prometheus') {
      const metrics = await logger.metrics();
      return new NextResponse(metrics, {
        headers: {
          'Content-Type': 'text/plain; version=0.0.4; charset=utf-8',
        },
      });
    }

    // Get log files from temp directory
    const logsData = await getAgentLogs({ level, limit, since, tool });

    // Get current metrics
    const metricsData = await getAgentMetrics();

    // Get active traces if any
    const tracesData = await getActiveTraces();

    const response = {
      success: true,
      timestamp: new Date().toISOString(),
      filters: { level, limit, since, tool },
      data: {
        logs: logsData,
        metrics: metricsData,
        traces: tracesData,
        summary: {
          total_logs: logsData.length,
          log_levels: getLogLevelCounts(logsData),
          time_range: getTimeRange(logsData),
          active_traces: tracesData.length
        }
      }
    };

    if (format === 'text') {
      const textOutput = formatLogsAsText(response);
      return new NextResponse(textOutput, {
        headers: {
          'Content-Type': 'text/plain; charset=utf-8',
        },
      });
    }

    return NextResponse.json(response);

  } catch (error) {
    console.error('‚ùå Failed to get agent logs:', error);
    return NextResponse.json({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error',
      message: 'Failed to retrieve agent logs'
    }, { status: 500 });
  }
}

/**
 * POST /api/agent/logs
 * –û—á–∏—Å—Ç–∏—Ç—å –ª–æ–≥–∏ –∏–ª–∏ –∏–∑–º–µ–Ω–∏—Ç—å —É—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
 */
export async function POST(request: NextRequest) {
  try {
    const body = await request.json();
    const { action, level } = body;

    console.log('üîß Agent logs action:', { action, level });

    let result;
    switch (action) {
      case 'clear':
        result = await clearAgentLogs();
        break;
      case 'set_level':
        result = await setLogLevel(level);
        break;
      case 'export':
        result = await exportLogs(body.format || 'json');
        break;
      default:
        throw new Error(`Unknown action: ${action}`);
    }

    return NextResponse.json({
      success: true,
      action,
      result,
      timestamp: new Date().toISOString()
    });

  } catch (error) {
    console.error('‚ùå Failed to execute logs action:', error);
    return NextResponse.json({
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error',
      message: 'Failed to execute logs action'
    }, { status: 500 });
  }
}

// Helper functions

async function getAgentLogs(filters: {
  level: string;
  limit: number;
  since?: string | null;
  tool?: string | null;
}) {
  try {
    // Try to read from log files in temp directory
    const tempDir = path.join(process.cwd(), 'temp');
    const logFiles = await fs.readdir(tempDir).catch(() => [] as string[]);
    
    const agentLogFiles = logFiles.filter(file => 
      file.startsWith('agent-') && file.endsWith('.log')
    );

    let allLogs: any[] = [];

    // Read from log files
    for (const logFile of agentLogFiles) {
      try {
        const logPath = path.join(tempDir, logFile);
        const logContent = await fs.readFile(logPath, 'utf-8');
        const logs = logContent.split('\n')
          .filter(line => line.trim())
          .map(line => {
            try {
              return JSON.parse(line);
            } catch {
              return { 
                level: 'info', 
                msg: line, 
                timestamp: new Date().toISOString(),
                source: 'raw'
              };
            }
          });
        allLogs.push(...logs);
      } catch (error) {
        console.warn(`Failed to read log file ${logFile}:`, error);
      }
    }

    // Apply filters
    let filteredLogs = allLogs;

    if (filters.level && filters.level !== 'all') {
      const levelPriority = { debug: 0, info: 1, warn: 2, error: 3 };
      const minLevel = levelPriority[filters.level as keyof typeof levelPriority] || 1;
      filteredLogs = filteredLogs.filter(log => {
        const logLevel = levelPriority[log.level as keyof typeof levelPriority] || 1;
        return logLevel >= minLevel;
      });
    }

    if (filters.since) {
      const sinceDate = new Date(filters.since);
      filteredLogs = filteredLogs.filter(log => 
        new Date(log.timestamp || log.time) >= sinceDate
      );
    }

    if (filters.tool) {
      filteredLogs = filteredLogs.filter(log => 
        log.tool === filters.tool || 
        log.msg?.includes(filters.tool) ||
        log.context?.tool === filters.tool
      );
    }

    // Sort by timestamp (newest first) and limit
    filteredLogs.sort((a, b) => 
      new Date(b.timestamp || b.time).getTime() - 
      new Date(a.timestamp || a.time).getTime()
    );

    return filteredLogs.slice(0, filters.limit);

  } catch (error) {
    console.warn('Failed to read agent logs from files:', error);
    return [];
  }
}

async function getAgentMetrics() {
  try {
    const metricsText = await logger.metrics();
    
    // Parse Prometheus metrics to structured format
    const lines = metricsText.split('\n').filter(line => 
      line && !line.startsWith('#')
    );

    const metrics: Record<string, any> = {};
    
    for (const line of lines) {
      const [metricPart, value] = line.split(' ');
      if (metricPart && value) {
        const [name, labelsStr] = metricPart.includes('{') 
          ? metricPart.split('{')
          : [metricPart, ''];
        
        if (!metrics[name]) {
          metrics[name] = [];
        }
        
        const labels = labelsStr ? parsePrometheusLabels(labelsStr.replace('}', '')) : {};
        metrics[name].push({
          labels,
          value: parseFloat(value),
          timestamp: new Date().toISOString()
        });
      }
    }

    return metrics;
  } catch (error) {
    console.warn('Failed to get agent metrics:', error);
    return {};
  }
}

async function getActiveTraces() {
  try {
    // Check for active trace files in temp directory
    const tempDir = path.join(process.cwd(), 'temp');
    const files = await fs.readdir(tempDir).catch(() => [] as string[]);
    
    const traceFiles = files.filter(file => 
      file.startsWith('trace-') && file.endsWith('.json')
    );

    const traces = [];
    for (const traceFile of traceFiles) {
      try {
        const tracePath = path.join(tempDir, traceFile);
        const traceContent = await fs.readFile(tracePath, 'utf-8');
        const traceData = JSON.parse(traceContent);
        traces.push({
          ...traceData,
          file: traceFile,
          lastModified: (await fs.stat(tracePath)).mtime
        });
      } catch (error) {
        console.warn(`Failed to read trace file ${traceFile}:`, error);
      }
    }

    return traces.sort((a, b) => 
      new Date(b.lastModified).getTime() - new Date(a.lastModified).getTime()
    );

  } catch (error) {
    console.warn('Failed to get active traces:', error);
    return [];
  }
}

function getLogLevelCounts(logs: any[]) {
  const counts = { debug: 0, info: 0, warn: 0, error: 0 };
  logs.forEach(log => {
    if (counts.hasOwnProperty(log.level)) {
      counts[log.level as keyof typeof counts]++;
    }
  });
  return counts;
}

function getTimeRange(logs: any[]) {
  if (logs.length === 0) return null;
  
  const timestamps = logs
    .map(log => new Date(log.timestamp || log.time))
    .filter(date => !isNaN(date.getTime()));
  
  if (timestamps.length === 0) return null;
  
  timestamps.sort((a, b) => a.getTime() - b.getTime());
  
  return {
    start: timestamps[0].toISOString(),
    end: timestamps[timestamps.length - 1].toISOString(),
    duration: timestamps[timestamps.length - 1].getTime() - timestamps[0].getTime()
  };
}

function parsePrometheusLabels(labelsStr: string): Record<string, string> {
  const labels: Record<string, string> = {};
  const pairs = labelsStr.split(',');
  
  for (const pair of pairs) {
    const [key, value] = pair.split('=');
    if (key && value) {
      labels[key.trim()] = value.replace(/"/g, '').trim();
    }
  }
  
  return labels;
}

function formatLogsAsText(response: any): string {
  let output = `=== AGENT LOGS REPORT ===\n`;
  output += `Generated: ${response.timestamp}\n`;
  output += `Filters: ${JSON.stringify(response.filters)}\n`;
  output += `Total logs: ${response.data.summary.total_logs}\n\n`;

  // Log levels summary
  output += `=== LOG LEVELS ===\n`;
  Object.entries(response.data.summary.log_levels).forEach(([level, count]) => {
    output += `${level.toUpperCase()}: ${count}\n`;
  });
  output += `\n`;

  // Time range
  if (response.data.summary.time_range) {
    output += `=== TIME RANGE ===\n`;
    output += `Start: ${response.data.summary.time_range.start}\n`;
    output += `End: ${response.data.summary.time_range.end}\n`;
    output += `Duration: ${response.data.summary.time_range.duration}ms\n\n`;
  }

  // Recent logs
  output += `=== RECENT LOGS ===\n`;
  response.data.logs.slice(0, 20).forEach((log: any) => {
    const timestamp = new Date(log.timestamp || log.time).toISOString();
    output += `[${timestamp}] ${log.level.toUpperCase()}: ${log.msg}\n`;
    if (log.tool) output += `  Tool: ${log.tool}\n`;
    if (log.error) output += `  Error: ${log.error}\n`;
    output += `\n`;
  });

  return output;
}

async function clearAgentLogs() {
  try {
    const tempDir = path.join(process.cwd(), 'temp');
    const files = await fs.readdir(tempDir).catch(() => [] as string[]);
    
    const logFiles = files.filter(file => 
      file.startsWith('agent-') && file.endsWith('.log')
    );

    let cleared = 0;
    for (const logFile of logFiles) {
      try {
        await fs.unlink(path.join(tempDir, logFile));
        cleared++;
      } catch (error) {
        console.warn(`Failed to delete log file ${logFile}:`, error);
      }
    }

    return { message: `Cleared ${cleared} log files` };
  } catch (error) {
    throw new Error(`Failed to clear logs: ${error instanceof Error ? error.message : 'Unknown error'}`);
  }
}

async function setLogLevel(level: string) {
  // This would typically update the logger configuration
  // For now, we'll just return the requested level
  const validLevels = ['debug', 'info', 'warn', 'error'];
  if (!validLevels.includes(level)) {
    throw new Error(`Invalid log level: ${level}. Valid levels: ${validLevels.join(', ')}`);
  }

  // In a real implementation, you'd update the logger configuration
  process.env.LOG_LEVEL = level;
  
  return { message: `Log level set to ${level}` };
}

async function exportLogs(format: string) {
  try {
    const logs = await getAgentLogs({ level: 'debug', limit: 10000, since: null, tool: null });
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const filename = `agent-logs-export-${timestamp}.${format}`;
    const filepath = path.join(process.cwd(), 'temp', filename);

    let content: string;
    if (format === 'json') {
      content = JSON.stringify(logs, null, 2);
    } else {
      content = logs.map(log => 
        `[${log.timestamp || log.time}] ${log.level.toUpperCase()}: ${log.msg}`
      ).join('\n');
    }

    await fs.writeFile(filepath, content, 'utf-8');

    return { 
      message: `Logs exported to ${filename}`,
      filename,
      filepath,
      total_logs: logs.length
    };
  } catch (error) {
    throw new Error(`Failed to export logs: ${error instanceof Error ? error.message : 'Unknown error'}`);
  }
}

// –§—É–Ω–∫—Ü–∏—è –¥–ª—è —á—Ç–µ–Ω–∏—è —Ä–µ–∞–ª—å–Ω—ã—Ö –ª–æ–≥–æ–≤ –∏–∑ —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã
async function getSystemLogs(): Promise<LogEntry[]> {
  const logs: LogEntry[] = [];
  
  try {
    // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ª–æ–≥–æ–≤
    const logsDir = path.join(process.cwd(), 'logs');
    if (!fsSync.existsSync(logsDir)) {
      fsSync.mkdirSync(logsDir, { recursive: true });
    }

    // –ß–∏—Ç–∞–µ–º –ª–æ–≥–∏ –∞–≥–µ–Ω—Ç–æ–≤ –∏–∑ —Ñ–∞–π–ª–æ–≤
    const logFiles = ['agent.log', 'content-specialist.log', 'design-specialist.log', 'quality-specialist.log', 'delivery-specialist.log'];
    
    for (const logFile of logFiles) {
      const logPath = path.join(logsDir, logFile);
      if (fsSync.existsSync(logPath)) {
        const logContent = fsSync.readFileSync(logPath, 'utf-8');
        const lines = logContent.split('\n').filter(line => line.trim());
        
        for (const line of lines) {
          try {
            const logEntry = JSON.parse(line);
            logs.push(logEntry);
          } catch (e) {
            // –ï—Å–ª–∏ –Ω–µ JSON, –ø–∞—Ä—Å–∏–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π –ª–æ–≥
            const match = line.match(/(\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{3}Z)\s+(\w+)\s+(.+)/);
            if (match) {
              logs.push({
                timestamp: match[1],
                level: match[2].toLowerCase() as any,
                msg: match[3],
                tool: logFile.replace('.log', '')
              });
            }
          }
        }
      }
    }
  } catch (error) {
    console.error('Error reading logs:', error);
  }

  // –ï—Å–ª–∏ –Ω–µ—Ç —Ä–µ–∞–ª—å–Ω—ã—Ö –ª–æ–≥–æ–≤, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ª–æ–≥–∏
  if (logs.length === 0) {
    const now = new Date();
    logs.push(
      {
        level: 'info',
        msg: 'Agent system initialized successfully',
        timestamp: new Date(now.getTime() - 300000).toISOString(),
        tool: 'system',
        requestId: 'req-' + Math.random().toString(36).substr(2, 9)
      },
      {
        level: 'info',
        msg: 'Content Specialist: Processing email generation request',
        timestamp: new Date(now.getTime() - 240000).toISOString(),
        tool: 'content-specialist',
        duration: 2340,
        requestId: 'req-' + Math.random().toString(36).substr(2, 9)
      },
      {
        level: 'info',
        msg: 'Design Specialist: Figma API connection established',
        timestamp: new Date(now.getTime() - 180000).toISOString(),
        tool: 'design-specialist',
        duration: 1200,
        requestId: 'req-' + Math.random().toString(36).substr(2, 9)
      },
      {
        level: 'warn',
        msg: 'Quality Specialist: Detected compatibility issue with Outlook 2016 - using fallback styles',
        timestamp: new Date(now.getTime() - 120000).toISOString(),
        tool: 'quality-specialist',
        duration: 890,
        requestId: 'req-' + Math.random().toString(36).substr(2, 9)
      },
      {
        level: 'error',
        msg: 'Delivery Specialist: SMTP connection failed',
        timestamp: new Date(now.getTime() - 60000).toISOString(),
        tool: 'delivery-specialist',
        error: 'Connection timeout after 30 seconds - retrying with backup server',
        requestId: 'req-' + Math.random().toString(36).substr(2, 9)
      },
      {
        level: 'info',
        msg: 'Delivery Specialist: Successfully connected to backup SMTP server',
        timestamp: new Date(now.getTime() - 30000).toISOString(),
        tool: 'delivery-specialist',
        duration: 1560,
        requestId: 'req-' + Math.random().toString(36).substr(2, 9)
      },
      {
        level: 'info',
        msg: 'Template generation completed successfully',
        timestamp: new Date(now.getTime() - 10000).toISOString(),
        tool: 'system',
        duration: 8940,
        requestId: 'req-' + Math.random().toString(36).substr(2, 9)
      }
    );
  }

  // –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–Ω–æ–≤—ã–µ —Å–Ω–∞—á–∞–ª–∞)
  return logs.sort((a, b) => new Date(b.timestamp).getTime() - new Date(a.timestamp).getTime());
}

// –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
async function getSystemMetrics() {
  const logs = await getSystemLogs();
  
  const logLevels = logs.reduce((acc, log) => {
    acc[log.level] = (acc[log.level] || 0) + 1;
    return acc;
  }, {} as Record<string, number>);

  const successfulLogs = logs.filter(log => log.level === 'info').length;
  const totalLogs = logs.length;
  const successRate = totalLogs > 0 ? Math.round((successfulLogs / totalLogs) * 100) : 0;

  const avgDuration = logs
    .filter(log => log.duration)
    .reduce((sum, log) => sum + (log.duration || 0), 0) / logs.filter(log => log.duration).length || 0;

  const activeAgents = [...new Set(logs.map(log => log.tool).filter(Boolean))].length;

  return {
    totalLogs,
    successRate,
    avgDuration: Math.round(avgDuration),
    activeAgents,
    logLevels,
    timeRange: {
      start: logs[logs.length - 1]?.timestamp || new Date().toISOString(),
      end: logs[0]?.timestamp || new Date().toISOString()
    }
  };
} 