import { NextRequest, NextResponse } from 'next/server';
import fs from 'fs/promises';
import fsSync from 'fs';
import path from 'path';

interface LogEntry {
  level: 'debug' | 'info' | 'warn' | 'error';
  msg: string;
  timestamp: string;
  tool?: string;
  error?: string;
  duration?: number;
  requestId?: string;
  userId?: string;
}

interface AgentLog {
  timestamp: string;
  level: 'info' | 'warn' | 'error';
  message: string;
  agent?: string;
  tool?: string;
  traceId?: string;
  details?: any;
}

// interface LogsResponse {
//   success: boolean;
//   logs: AgentLog[];
//   total_count: number;
//   filtered_count: number;
//   trace_id?: string;
//   timestamp: string;
// }

// Phase 3.3.6: Performance Debugging Interfaces
interface PerformanceProfile {
  id: string;
  agent_id: string;
  start_time: string;
  end_time?: string;
  status: 'active' | 'completed' | 'error';
  config: ProfilingConfig;
  data: {
    execution_times: ExecutionTiming[];
    memory_snapshots: MemorySnapshot[];
    resource_usage: ResourceUsage[];
    call_stack: CallStackEntry[];
    bottlenecks: Bottleneck[];
  };
}

interface ProfilingConfig {
  agent_id: string;
  duration_ms?: number;
  sample_interval_ms?: number;
  include_memory?: boolean;
  include_cpu?: boolean;
  include_network?: boolean;
  include_call_stack?: boolean;
  _filters?: {
    min_duration_ms?: number;
    operation_types?: string[];
  };
}

interface ExecutionTiming {
  timestamp: string;
  operation: string;
  duration_ms: number;
  agent_id: string;
  tool_id?: string;
  status: 'success' | 'error' | 'timeout';
  metadata: any;
}

interface MemorySnapshot {
  timestamp: string;
  heap_used_mb: number;
  heap_total_mb: number;
  external_mb: number;
  array_buffers_mb: number;
  gc_stats?: {
    collections: number;
    time_ms: number;
  };
}

interface ResourceUsage {
  timestamp: string;
  cpu_percent: number;
  memory_percent: number;
  network_io: {
    bytes_sent: number;
    bytes_received: number;
    requests_count: number;
  };
  disk_io?: {
    reads: number;
    writes: number;
  };
}

interface CallStackEntry {
  timestamp: string;
  function_name: string;
  file_path: string;
  line_number: number;
  execution_time_ms: number;
  parameters?: any;
  return_value?: any;
}

interface Bottleneck {
  id: string;
  type: 'cpu' | 'memory' | 'network' | 'database' | 'external_api';
  severity: 'low' | 'medium' | 'high' | 'critical';
  description: string;
  detected_at: string;
  affected_operations: string[];
  impact_score: number;
  recommendations: string[];
}

interface DebugSession {
  id: string;
  agent_id: string;
  created_at: string;
  status: 'active' | 'paused' | 'completed';
  breakpoints: Breakpoint[];
  variables: VariableWatch[];
  call_stack: CallStackEntry[];
  execution_log: ExecutionLogEntry[];
}

interface Breakpoint {
  id: string;
  file_path: string;
  line_number: number;
  condition?: string;
  hit_count: number;
  enabled: boolean;
}

interface VariableWatch {
  name: string;
  value: any;
  type: string;
  scope: 'local' | 'global' | 'parameter';
  last_changed: string;
}

interface ExecutionLogEntry {
  timestamp: string;
  level: 'trace' | 'debug' | 'info' | 'warn' | 'error';
  message: string;
  context: any;
}

interface PerformanceAnalysis {
  agent_id: string;
  analysis_period: {
    start: string;
    end: string;
  };
  overall_score: number;
  metrics: {
    avg_response_time_ms: number;
    p95_response_time_ms: number;
    p99_response_time_ms: number;
    error_rate_percent: number;
    throughput_per_minute: number;
    memory_efficiency_score: number;
    cpu_efficiency_score: number;
  };
  trends: {
    response_time_trend: 'improving' | 'stable' | 'degrading';
    error_rate_trend: 'improving' | 'stable' | 'degrading';
    memory_trend: 'improving' | 'stable' | 'degrading';
  };
  recommendations: PerformanceRecommendation[];
  bottlenecks: Bottleneck[];
}

interface PerformanceRecommendation {
  id: string;
  category: 'performance' | 'memory' | 'error_handling' | 'architecture';
  priority: 'low' | 'medium' | 'high' | 'critical';
  title: string;
  description: string;
  impact_estimate: string;
  implementation_effort: 'low' | 'medium' | 'high';
  code_examples?: string[];
}

// In-memory storage for logs and performance data (in production, use Redis, ElasticSearch, or similar)
const logsStore = new Map<string, AgentLog[]>();
const performanceProfiles = new Map<string, PerformanceProfile>();
const debugSessions = new Map<string, DebugSession>();

/**
 * GET /api/agent/logs
 * Enhanced log retrieval with advanced filtering and search capabilities
 */
export async function GET(_request: NextRequest) {
  try {
    const { searchParams } = new URL(_request.url);
    const traceId = searchParams.get('traceId');
    const limit = parseInt(searchParams.get('limit') || '50');
    const level = searchParams.get('level') || 'all';
    const agent = searchParams.get('agent');
    const tool = searchParams.get('tool');
    const since = searchParams.get('since'); // ISO timestamp
    const until = searchParams.get('until'); // ISO timestamp
    const search = searchParams.get('search'); // Search query
    const requestId = searchParams.get('requestId'); // Filter by request ID
    const userId = searchParams.get('userId'); // Filter by user ID
    const minDuration = parseInt(searchParams.get('minDuration') || '0');
    const maxDuration = parseInt(searchParams.get('maxDuration') || '0');
    const sortBy = searchParams.get('sortBy') || 'timestamp';
    const sortOrder = searchParams.get('sortOrder') || 'desc';
    const format = searchParams.get('format') || 'json';
    const includeContext = searchParams.get('includeContext') === 'true';
    const highlightSearch = searchParams.get('highlightSearch') === 'true';

    console.log('üìã Enhanced logs _request: ', { 
      traceId, limit, level, agent, tool, since, until, search, 
      requestId, userId, minDuration, maxDuration, sortBy, sortOrder,
      format, includeContext, highlightSearch
    });

    let logs: AgentLog[] = [];

    if (traceId) {
      // Get logs for specific trace ID
      logs = logsStore.get(traceId) || [];
      
      // If no logs exist for this trace, generate some sample logs
      if (logs.length === 0) {
        logs = generateSampleLogs(traceId);
        logsStore.set(traceId, logs);
      }
    } else {
      // Get all logs from memory store and file system
      const allTraceLogs = Array.from(logsStore.values()).flat();
      const systemLogs = await getSystemLogs();
      const combinedLogs = [...allTraceLogs, ...systemLogs.map(log => ({
        timestamp: log.timestamp,
        level: log.level as 'info' | 'warn' | 'error',
        message: log.msg,
        agent: log.tool,
        tool: log.tool,
        traceId: log.requestId,
        details: {
          duration: log.duration,
          error: log.error,
          userId: log.userId
        }
      }))];
      
      // Remove duplicates based on timestamp and message
      const uniqueLogs = combinedLogs.filter((log, index, array) => 
        array.findIndex(l => l.timestamp === log.timestamp && l.message === log.message) === index
      );
      
      logs = uniqueLogs as AgentLog[];
    }

    // Apply enhanced _filters
    let filteredLogs = logs;
    const originalCount = logs.length;

    // Level filtering with hierarchy support
    if (level !== 'all') {
      const levelHierarchy = { debug: 0, info: 1, warn: 2, error: 3 };
      if (level.endsWith('+')) {
        const baseLevel = level.slice(0, -1) as keyof typeof levelHierarchy;
        const minLevel = levelHierarchy[baseLevel];
        filteredLogs = filteredLogs.filter(log => 
          levelHierarchy[log.level as keyof typeof levelHierarchy] >= minLevel
        );
      } else {
        filteredLogs = filteredLogs.filter(log => log.level === level);
      }
    }

    // Agent/Tool filtering
    if (agent) {
      filteredLogs = filteredLogs.filter(log => 
        log.agent === agent || log.tool === agent
      );
    }

    if (tool) {
      filteredLogs = filteredLogs.filter(log => log.tool === tool);
    }

    // Time range filtering
    if (since) {
      const sinceDate = new Date(since);
      filteredLogs = filteredLogs.filter(log => new Date(log.timestamp) >= sinceDate);
    }

    if (until) {
      const untilDate = new Date(until);
      filteredLogs = filteredLogs.filter(log => new Date(log.timestamp) <= untilDate);
    }

    // Request/User ID filtering
    if (requestId) {
      filteredLogs = filteredLogs.filter(log => 
        log.traceId?.includes(requestId) || 
        (log.details as any)?.requestId?.includes(requestId)
      );
    }

    if (userId) {
      filteredLogs = filteredLogs.filter(log => 
        (log.details as any)?.userId === userId
      );
    }

    // Duration filtering
    if (minDuration > 0) {
      filteredLogs = filteredLogs.filter(log => 
        (log.details as any)?.duration >= minDuration
      );
    }

    if (maxDuration > 0) {
      filteredLogs = filteredLogs.filter(log => 
        (log.details as any)?.duration <= maxDuration
      );
    }

    // Advanced search functionality
    if (search) {
      const searchTerms = search.toLowerCase().split(' ').filter(term => term.length > 0);
      filteredLogs = filteredLogs.filter(log => {
        const searchableText = [
          log.message,
          log.agent,
          log.tool,
          log.traceId,
          (log.details as any)?.error,
          JSON.stringify(log.details)
        ].filter(Boolean).join(' ').toLowerCase();
        
        return searchTerms.every(term => searchableText.includes(term));
      });

      // Highlight search terms if requested
      if (highlightSearch) {
        filteredLogs = filteredLogs.map(log => ({
          ...log,
          message: highlightSearchTerms(log.message, searchTerms),
          highlighted: true
        }));
      }
    }

    // Advanced sorting
    filteredLogs.sort((a, b) => {
      let aValue, bValue;
      
      switch (sortBy) {
        case 'level':
          const levelPriority = { debug: 0, info: 1, warn: 2, error: 3 };
          aValue = levelPriority[a.level as keyof typeof levelPriority];
          bValue = levelPriority[b.level as keyof typeof levelPriority];
          break;
        case 'agent':
          aValue = a.agent || '';
          bValue = b.agent || '';
          break;
        case 'duration':
          aValue = (a.details as any)?.duration || 0;
          bValue = (b.details as any)?.duration || 0;
          break;
        case 'timestamp':
        default:
          aValue = new Date(a.timestamp).getTime();
          bValue = new Date(b.timestamp).getTime();
          break;
      }
      
      const comparison = aValue < bValue ? -1 : aValue > bValue ? 1 : 0;
      return sortOrder === 'desc' ? -comparison : comparison;
    });

    // Apply pagination
    const totalFiltered = filteredLogs.length;
    const limitedLogs = filteredLogs.slice(0, limit);
    
    // Calculate statistics
    const logLevelCounts = getLogLevelCounts(filteredLogs);
    const timeRange = getTimeRange(filteredLogs);
    const agentCounts = getAgentCounts(filteredLogs);
    const performanceStats = getPerformanceStats(filteredLogs);

    // Prepare enhanced response
    const response = {
      success: true,
      _data: {
        logs: limitedLogs,
        metrics: {
          totalLogs: logs.length,
          filteredLogs: totalFiltered,
          displayedLogs: limitedLogs.length,
          successRate: calculateSuccessRate(filteredLogs),
          avgDuration: performanceStats.avgDuration,
          activeAgents: Object.keys(agentCounts).length
        },
        summary: {
          total_logs: originalCount,
          filtered_logs: totalFiltered,
          displayed_logs: limitedLogs.length,
          log_levels: logLevelCounts,
          time_range: timeRange,
          active_traces: Object.keys(agentCounts).length,
          agent_distribution: agentCounts,
          performance_stats: performanceStats
        },
        traces: await getActiveTraces(),
        _filters_applied: {
          level,
          agent,
          tool,
          search,
          time_range: { since, until },
          duration_range: { min: minDuration, max: maxDuration },
          request_id: requestId,
          user_id: userId
        },
        sorting: { sortBy, sortOrder },
        pagination: {
          limit,
          has_more: totalFiltered > limit,
          next_offset: limit
        }
      },
      metadata: {
        trace_id: traceId || undefined,
        timestamp: new Date().toISOString(),
        format,
        include_context: includeContext,
        highlight_search: highlightSearch,
        api_version: '3.3.4'
      }
    };

    // Return different formats based on request
    if (format === 'text') {
      const textOutput = formatLogsAsAdvancedText(response);
      return new NextResponse(textOutput, {
        headers: {
          'Content-Type': 'text/plain',
          'Content-Disposition': `attachment; filename="agent-logs-${new Date().toISOString().split('T')[0]}.txt"`
        }
      });
    }

    return NextResponse.json(response);

  } catch (error) {
    console.error('‚ùå Failed to get agent logs:', error);
    return NextResponse.json({
      success: false,
      error: error instanceof Error ? error instanceof Error ? error.message : String(error) : 'Unknown error',
      message: 'Failed to retrieve agent logs'
    }, { status: 500 });
  }
}

/**
 * POST /api/agent/logs
 * Enhanced log management with advanced actions and error tracking
 */
export async function POST(_request: NextRequest) {
  try {
    const body = await _request.json();
    const { action, traceId, level, message, agent, tool, details, _filters } = body;
    
    console.log('üîß Enhanced log action:', { action, traceId, _filters });
    
    // Handle different actions
    switch (action) {
      case 'add':
        return await addLogEntry({ traceId, level, message, agent, tool, details });
      case 'clear':
        return await clearLogs(_filters);
      case 'export':
        return await exportFilteredLogs(_filters, body.format || 'json');
      case 'search':
        return await performAdvancedSearch(body.searchConfig);
      case 'analyze':
        return await analyzeLogPatterns(_filters);
      case 'archive':
        return await archiveLogs(_filters);
      case 'track_error':
        return await trackError(body.errorData);
      case 'get_alerts':
        return await getActiveAlerts(_filters);
      case 'create_alert':
        return await createAlert(body.alertConfig);
      case 'update_alert':
        return await updateAlert(body.alertId, body.alertConfig);
      case 'delete_alert':
        return await deleteAlert(body.alertId);
      // New Phase 3.3.6: Agent Performance Debugging Tools
      case 'start_profiling':
        return await startPerformanceProfiling(body.profilingConfig);
      case 'stop_profiling':
        return await stopPerformanceProfiling(body.profilingId);
      case 'get_profiling_data':
        return await getProfilingData(body.profilingId);
      case 'analyze_performance':
        return await analyzeAgentPerformance(body.analysisConfig);
      case 'get_performance_metrics':
        return await getPerformanceMetrics(body.metricsConfig);
      case 'debug_agent':
        return await debugAgent(body._agentId, body.debugConfig);
      case 'get_debug_session':
        return await getDebugSession(body.sessionId);
      case 'trace_execution':
        return await traceAgentExecution(body.traceConfig);
      case 'memory_analysis':
        return await analyzeMemoryUsage(body.analysisConfig);
      case 'bottleneck_detection':
        return await detectBottlenecks(body.detectionConfig);
      case 'resource_monitoring':
        return await monitorResources(body.monitoringConfig);
      default:
        // Legacy support for direct log addition
        return await addLogEntry({ traceId, level, message, agent, tool, details });
    }
    
  } catch (error) {
    console.error('‚ùå Failed to execute log action:', error);
    return NextResponse.json({
      success: false,
      error: error instanceof Error ? error instanceof Error ? error.message : String(error) : 'Unknown error',
      message: 'Failed to execute log action'
    }, { status: 500 });
  }
}

// Enhanced log management functions
async function addLogEntry(_params: {
  traceId: string;
  level: string;
  message: string;
  agent?: string;
  tool?: string;
  details?: any;
}) {
  const { traceId, level, message, agent, tool, details } = _params;

  if (!traceId || !level || !message) {
    return NextResponse.json({
      success: false,
      error: 'Missing required parameters',
      message: 'traceId, level, and message are required'
    }, { status: 400 });
  }

  const logEntry: AgentLog = {
    timestamp: new Date().toISOString(),
    level: level as 'info' | 'warn' | 'error',
    message,
    ...(agent && { agent }),
    ...(tool && { tool }),
    traceId,
    details
  };

  console.log('üìù New log entry:', logEntry);

  // Get existing logs for trace ID
  const existingLogs = logsStore.get(traceId) || [];
  existingLogs.push(logEntry);
  
  // Keep only last 1000 logs per trace to prevent memory issues
  if (existingLogs.length > 1000) {
    existingLogs.splice(0, existingLogs.length - 1000);
  }
  
  logsStore.set(traceId, existingLogs);

  return NextResponse.json({
    success: true,
    log_entry: logEntry,
    total_logs: existingLogs.length,
    timestamp: new Date().toISOString()
  });
}

// Enhanced log management functions
async function clearLogs(_filters?: any) {
  try {
    let clearedCount = 0;
    
    if (_filters?.traceId) {
      // Clear specific trace
      if (logsStore.has(_filters.traceId)) {
        clearedCount = logsStore.get(_filters.traceId)?.length || 0;
        logsStore.delete(_filters.traceId);
      }
    } else if (_filters?.level || _filters?.agent || _filters?.timeRange) {
      // Clear filtered logs
      for (const [_traceId, logs] of logsStore.entries()) {
        const filteredLogs = logs.filter(log => {
          if (_filters.level && log.level !== _filters.level) return true;
          if (_filters.agent && log.agent !== _filters.agent) return true;
          if (_filters.timeRange?.since && new Date(log.timestamp) < new Date(_filters.timeRange.since)) return true;
          if (_filters.timeRange?.until && new Date(log.timestamp) > new Date(_filters.timeRange.until)) return true;
          return false;
        });
        
        clearedCount += logs.length - filteredLogs.length;
        if (filteredLogs.length === 0) {
          logsStore.delete(_traceId);
        } else {
          logsStore.set(_traceId, filteredLogs);
        }
      }
    } else {
      // Clear all logs
      for (const [_traceId, logs] of logsStore.entries()) {
        clearedCount += logs.length;
      }
      logsStore.clear();
    }
    
    return NextResponse.json({
      success: true,
      message: `Cleared ${clearedCount} log entries`,
      cleared_count: clearedCount,
      timestamp: new Date().toISOString()
    });
    
  } catch (error) {
    throw new Error(`Failed to clear logs: ${error instanceof Error ? error instanceof Error ? error.message : String(error) : 'Unknown error'}`);
  }
}

async function exportFilteredLogs(_filters: any, format: string = 'json') {
  try {
    // Get all logs and apply _filters
    const allLogs = Array.from(logsStore.values()).flat();
    const systemLogs = await getSystemLogs();
    const combinedLogs = [...allLogs, ...systemLogs.map(log => ({
      timestamp: log.timestamp,
      level: log.level as 'info' | 'warn' | 'error',
      message: log.msg,
      agent: log.tool,
      tool: log.tool,
      traceId: log.requestId,
      details: {
        duration: log.duration,
        error: log.error,
        userId: log.userId
      }
    }))];
    
    // Apply _filters (simplified version)
    let filteredLogs = combinedLogs;
    
    if (_filters?.level && _filters.level !== 'all') {
      filteredLogs = filteredLogs.filter(log => log.level === _filters.level);
    }
    
    if (_filters?.agent) {
      filteredLogs = filteredLogs.filter(log => log.agent === _filters.agent);
    }
    
    if (_filters?.timeRange?.since) {
      const sinceDate = new Date(_filters.timeRange.since);
      filteredLogs = filteredLogs.filter(log => new Date(log.timestamp) >= sinceDate);
    }
    
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const filename = `agent-logs-filtered-${timestamp}.${format}`;
    
    return NextResponse.json({
      success: true,
      message: `Exported ${filteredLogs.length} filtered log entries`,
      exported_count: filteredLogs.length,
      filename,
      download_url: `/api/agent/logs/download?file=${filename}`,
      _filters_applied: _filters,
      timestamp: new Date().toISOString()
    });
    
  } catch (error) {
    throw new Error(`Failed to export logs: ${error instanceof Error ? error instanceof Error ? error.message : String(error) : 'Unknown error'}`);
  }
}

// Error tracking and alert system interfaces
interface ErrorTrackingData {
  errorId: string;
  message: string;
  level: 'error' | 'warn' | 'critical';
  agent: string;
  tool?: string;
  timestamp: string;
  context?: any;
  stackTrace?: string;
  userId?: string;
  sessionId?: string;
  frequency?: number;
}

interface Alert {
  id: string;
  name: string;
  type: 'error_threshold' | 'performance_degradation' | 'agent_down' | 'custom';
  enabled: boolean;
  conditions: {
    level?: string[];
    agent?: string[];
    error_rate_threshold?: number;
    response_time_threshold?: number;
    frequency_threshold?: number;
    time_window_minutes?: number;
  };
  actions: {
    notification: boolean;
    email?: string[];
    webhook?: string;
    escalation_timeout_minutes?: number;
  };
  created_at: string;
  last_triggered?: string;
  trigger_count: number;
  status: 'active' | 'triggered' | 'resolved' | 'snoozed';
}

// In-memory storage for error tracking and alerts
const errorStore = new Map<string, ErrorTrackingData[]>();
const alertStore = new Map<string, Alert>();
const alertTriggerStore = new Map<string, { count: number; lastTriggered: string }>();

// Error tracking functions
async function trackError(errorData: Partial<ErrorTrackingData>) {
  try {
    const errorId = errorData.errorId || `error-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
    const now = new Date().toISOString();
    
    const error: ErrorTrackingData = {
      errorId,
      message: errorData.message || 'Unknown error',
      level: errorData.level || 'error',
      agent: errorData.agent || 'unknown',
      ...(errorData.tool && { tool: errorData.tool }),
      timestamp: now,
      ...(errorData.context !== undefined && { context: errorData.context }),
      ...(errorData.stackTrace && { stackTrace: errorData.stackTrace }),
      ...(errorData.userId && { userId: errorData.userId }),
      ...(errorData.sessionId && { sessionId: errorData.sessionId }),
      frequency: 1
    };

    // Store error
    const agentErrors = errorStore.get(error.agent) || [];
    
    // Check for duplicate error (same message within last 5 minutes)
    const recentErrors = agentErrors.filter((e: any) => 
      e.message === error.message && 
      (new Date().getTime() - new Date(e.timestamp).getTime()) < 5 * 60 * 1000
    );
    
    if (recentErrors.length > 0) {
      // Update frequency of existing error
      const firstError = recentErrors[0];
      if (firstError) {
        firstError.frequency = (firstError.frequency || 1) + 1;
        firstError.timestamp = now;
      }
    } else {
      // Add new error
      agentErrors.push(error);
      
      // Keep only last 100 errors per agent
      if (agentErrors.length > 100) {
        agentErrors.splice(0, agentErrors.length - 100);
      }
    }
    
    errorStore.set(error.agent, agentErrors);

    // Check alerts for this error
    await checkAndTriggerAlerts(error);

    return NextResponse.json({
      success: true,
      error_tracked: error,
      total_errors_for_agent: agentErrors.length,
      timestamp: now
    });

  } catch (error) {
    throw new Error(`Failed to track error: ${error instanceof Error ? error instanceof Error ? error.message : String(error) : 'Unknown error'}`);
  }
}

// Alert management functions
async function getActiveAlerts(_filters?: any) {
  try {
    const allAlerts = Array.from(alertStore.values());
    
    let filteredAlerts = allAlerts;
    
    if (_filters?.status) {
      filteredAlerts = filteredAlerts.filter(alert => alert.status === _filters.status);
    }
    
    if (_filters?.type) {
      filteredAlerts = filteredAlerts.filter(alert => alert.type === _filters.type);
    }
    
    if (_filters?.enabled !== undefined) {
      filteredAlerts = filteredAlerts.filter(alert => alert.enabled === _filters.enabled);
    }

    // Get alert statistics
    const stats = {
      total_alerts: allAlerts.length,
      active_alerts: allAlerts.filter(a => a.enabled).length,
      triggered_alerts: allAlerts.filter(a => a.status === 'triggered').length,
      resolved_alerts: allAlerts.filter(a => a.status === 'resolved').length
    };

    return NextResponse.json({
      success: true,
      alerts: filteredAlerts,
      statistics: stats,
      timestamp: new Date().toISOString()
    });

  } catch (error) {
    throw new Error(`Failed to get alerts: ${error instanceof Error ? error instanceof Error ? error.message : String(error) : 'Unknown error'}`);
  }
}

async function createAlert(alertConfig: Partial<Alert>) {
  try {
    const alertId = `alert-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
    const now = new Date().toISOString();
    
    const alert: Alert = {
      id: alertId,
      name: alertConfig.name || 'Unnamed Alert',
      type: alertConfig.type || 'custom',
      enabled: alertConfig.enabled !== false,
      conditions: alertConfig.conditions || {},
      actions: alertConfig.actions || { notification: true },
      created_at: now,
      trigger_count: 0,
      status: 'active'
    };

    alertStore.set(alertId, alert);

    return NextResponse.json({
      success: true,
      alert_created: alert,
      message: `Alert "${alert.name}" created successfully`,
      timestamp: now
    });

  } catch (error) {
    throw new Error(`Failed to create alert: ${error instanceof Error ? error instanceof Error ? error.message : String(error) : 'Unknown error'}`);
  }
}

async function updateAlert(alertId: string, alertConfig: Partial<Alert>) {
  try {
    const existingAlert = alertStore.get(alertId);
    
    if (!existingAlert) {
      return NextResponse.json({
        success: false,
        error: 'Alert not found',
        message: `No alert found with ID: ${alertId}`
      }, { status: 404 });
    }

    const updatedAlert: Alert = {
      ...existingAlert,
      ...alertConfig,
      id: alertId, // Preserve original ID
      created_at: existingAlert.created_at // Preserve creation date
    };

    alertStore.set(alertId, updatedAlert);

    return NextResponse.json({
      success: true,
      alert_updated: updatedAlert,
      message: `Alert "${updatedAlert.name}" updated successfully`,
      timestamp: new Date().toISOString()
    });

  } catch (error) {
    throw new Error(`Failed to update alert: ${error instanceof Error ? error instanceof Error ? error.message : String(error) : 'Unknown error'}`);
  }
}

async function deleteAlert(alertId: string) {
  try {
    const existingAlert = alertStore.get(alertId);
    
    if (!existingAlert) {
      return NextResponse.json({
        success: false,
        error: 'Alert not found',
        message: `No alert found with ID: ${alertId}`
      }, { status: 404 });
    }

    alertStore.delete(alertId);
    alertTriggerStore.delete(alertId);

    return NextResponse.json({
      success: true,
      alert_deleted: existingAlert,
      message: `Alert "${existingAlert.name}" deleted successfully`,
      timestamp: new Date().toISOString()
    });

  } catch (error) {
    throw new Error(`Failed to delete alert: ${error instanceof Error ? error instanceof Error ? error.message : String(error) : 'Unknown error'}`);
  }
}

// Alert checking and triggering
async function checkAndTriggerAlerts(errorData: ErrorTrackingData) {
  try {
    const enabledAlerts = Array.from(alertStore.values()).filter(alert => alert.enabled);
    
    for (const alert of enabledAlerts) {
      const shouldTrigger = await evaluateAlertConditions(alert, errorData);
      
      if (shouldTrigger) {
        await triggerAlert(alert, errorData);
      }
    }

  } catch (error) {
    console.error('‚ùå Failed to check alerts:', error);
  }
}

async function evaluateAlertConditions(alert: Alert, errorData: ErrorTrackingData): Promise<boolean> {
  const { conditions } = alert;
  
  // Check level conditions
  if (conditions.level && conditions.level.length > 0) {
    if (!conditions.level.includes(errorData.level)) {
      return false;
    }
  }

  // Check agent conditions
  if (conditions.agent && conditions.agent.length > 0) {
    if (!conditions.agent.includes(errorData.agent)) {
      return false;
    }
  }

  // Check error rate threshold
  if (conditions.error_rate_threshold && conditions.time_window_minutes) {
    const windowStart = new Date(Date.now() - conditions.time_window_minutes * 60 * 1000);
    const agentErrors = errorStore.get(errorData.agent) || [];
    const recentErrors = agentErrors.filter(e => new Date(e.timestamp) >= windowStart);
    
    const errorRate = recentErrors.length / conditions.time_window_minutes;
    if (errorRate < conditions.error_rate_threshold) {
      return false;
    }
  }

  // Check frequency threshold for this specific error
  if (conditions.frequency_threshold) {
    if ((errorData.frequency || 1) < conditions.frequency_threshold) {
      return false;
    }
  }

  return true;
}

async function triggerAlert(alert: Alert, errorData: ErrorTrackingData) {
  try {
    const now = new Date().toISOString();
    
    // Update alert status and counts
    alert.status = 'triggered';
    alert.last_triggered = now;
    alert.trigger_count += 1;
    alertStore.set(alert.id, alert);

    // Record trigger
    alertTriggerStore.set(alert.id, {
      count: alert.trigger_count,
      lastTriggered: now
    });

    // Execute alert actions
    if (alert.actions.notification) {
      console.log(`üö® ALERT TRIGGERED: ${alert.name}`);
      console.log(`   Error: ${errorData.message}`);
      console.log(`   Agent: ${errorData.agent}`);
      console.log(`   Level: ${errorData.level}`);
      console.log(`   Time: ${errorData.timestamp}`);
    }

    // TODO: Implement additional alert actions (email, webhook, etc.)
    if (alert.actions.email && alert.actions.email.length > 0) {
      // Send email notifications
      console.log(`üìß Would send email to: ${alert.actions.email.join(', ')}`);
    }

    if (alert.actions.webhook) {
      // Send webhook notification
      console.log(`üîó Would send webhook to: ${alert.actions.webhook}`);
    }

  } catch (error) {
    console.error('‚ùå Failed to trigger alert:', error);
  }
}

async function performAdvancedSearch(searchConfig: any) {
  try {
    const {
      query,
      searchFields = ['message', 'agent', 'tool'],
      caseSensitive = false,
      regex = false,
      fuzzy = false,
      dateRange,
      logLevels = ['debug', 'info', 'warn', 'error'],
      limit = 100
    } = searchConfig;
    
    // Get all logs
    const allLogs = Array.from(logsStore.values()).flat();
    const systemLogs = await getSystemLogs();
    const combinedLogs = [...allLogs, ...systemLogs.map(log => ({
      timestamp: log.timestamp,
      level: log.level as 'info' | 'warn' | 'error',
      message: log.msg,
      agent: log.tool,
      tool: log.tool,
      traceId: log.requestId,
      details: {
        duration: log.duration,
        error: log.error,
        userId: log.userId
      }
    }))];
    
    // Perform advanced search
    let searchResults = combinedLogs;
    
    // Filter by log levels
    searchResults = searchResults.filter(log => logLevels.includes(log.level));
    
    // Filter by date range
    if (dateRange?.start) {
      searchResults = searchResults.filter(log => 
        new Date(log.timestamp) >= new Date(dateRange.start)
      );
    }
    
    if (dateRange?.end) {
      searchResults = searchResults.filter(log => 
        new Date(log.timestamp) <= new Date(dateRange.end)
      );
    }
    
    // Perform text search
    if (query) {
      searchResults = searchResults.filter(log => {
        const searchableText = searchFields.map((field: any) => {
          switch (field) {
            case 'message': return log.message;
            case 'agent': return log.agent;
            case 'tool': return log.tool;
            case 'details': return JSON.stringify(log.details);
            default: return '';
          }
        }).join(' ');
        
        if (regex) {
          try {
            const regexPattern = new RegExp(query, caseSensitive ? 'g' : 'gi');
            return regexPattern.test(searchableText);
          } catch {
            return false;
          }
        } else {
          const searchText = caseSensitive ? searchableText : searchableText.toLowerCase();
          const searchQuery = caseSensitive ? query : query.toLowerCase();
          
          if (fuzzy) {
            // Simple fuzzy search implementation
            return fuzzyMatch(searchText, searchQuery);
          } else {
            return searchText.includes(searchQuery);
          }
        }
      });
    }
    
    // Sort by relevance (timestamp for now)
    searchResults.sort((a, b) => new Date(b.timestamp).getTime() - new Date(a.timestamp).getTime());
    
    // Apply limit
    const limitedResults = searchResults.slice(0, limit);
    
    return NextResponse.json({
      success: true,
      search_config: searchConfig,
      results: {
        total_matches: searchResults.length,
        displayed_matches: limitedResults.length,
        logs: limitedResults,
        search_summary: {
          query,
          fields_searched: searchFields,
          case_sensitive: caseSensitive,
          regex_used: regex,
          fuzzy_search: fuzzy,
          date_range: dateRange,
          log_levels: logLevels
        }
      },
      timestamp: new Date().toISOString()
    });
    
  } catch (error) {
    throw new Error(`Advanced search failed: ${error instanceof Error ? error instanceof Error ? error.message : String(error) : 'Unknown error'}`);
  }
}

async function analyzeLogPatterns(_filters: any) {
  try {
    // Get filtered logs
    const allLogs = Array.from(logsStore.values()).flat();
    const systemLogs = await getSystemLogs();
    const combinedLogs = [...allLogs, ...systemLogs.map(log => ({
      timestamp: log.timestamp,
      level: log.level as 'info' | 'warn' | 'error',
      message: log.msg,
      agent: log.tool,
      tool: log.tool,
      traceId: log.requestId,
      details: {
        duration: log.duration,
        error: log.error,
        userId: log.userId
      }
    }))];
    
    // Analyze patterns
    const analysis = {
      log_level_distribution: getLogLevelCounts(combinedLogs),
      agent_activity: getAgentCounts(combinedLogs),
      temporal_patterns: getTemporalPatterns(combinedLogs),
      error_patterns: getErrorPatterns(combinedLogs),
      performance_patterns: getPerformancePatterns(combinedLogs),
      common_messages: getCommonMessages(combinedLogs),
      anomalies: detectAnomalies(combinedLogs)
    };
    
    return NextResponse.json({
      success: true,
      analysis,
      total_logs_analyzed: combinedLogs.length,
      analysis_timestamp: new Date().toISOString()
    });
    
  } catch (error) {
    throw new Error(`Log analysis failed: ${error instanceof Error ? error instanceof Error ? error.message : String(error) : 'Unknown error'}`);
  }
}

async function archiveLogs(_filters: any) {
  try {
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const archiveName = `logs-archive-${timestamp}`;
    
    // In a real implementation, you would move logs to long-term storage
    // For now, we'll simulate archiving by counting logs
    let archivedCount = 0;
    
    for (const [traceId, logs] of logsStore.entries()) {
      if (_filters?.olderThan) {
        const cutoffDate = new Date(_filters.olderThan);
        const oldLogs = logs.filter(log => new Date(log.timestamp) < cutoffDate);
        archivedCount += oldLogs.length;
        
        // Remove old logs from active storage
        const recentLogs = logs.filter(log => new Date(log.timestamp) >= cutoffDate);
        if (recentLogs.length === 0) {
          logsStore.delete(traceId);
        } else {
          logsStore.set(traceId, recentLogs);
        }
      }
    }
    
    return NextResponse.json({
      success: true,
      message: `Archived ${archivedCount} log entries`,
      archive_name: archiveName,
      archived_count: archivedCount,
      timestamp: new Date().toISOString()
    });
    
  } catch (error) {
    throw new Error(`Log archiving failed: ${error instanceof Error ? error instanceof Error ? error.message : String(error) : 'Unknown error'}`);
  }

}

// Legacy helper functions (maintained for backward compatibility)

// async function getAgentLogs(__filters: {
//   level: string;
//   limit: number;
//   since?: string | null;
//   tool?: string | null;
// }) {
//   try {
//     // Try to read from log files in temp directory
//     const tempDir = path.join(process.cwd(), 'temp');
//     const logFiles = await fs.readdir(tempDir).catch(() => [] as string[]);
//     
//     const agentLogFiles = logFiles.filter(file => 
//       file.startsWith('agent-') && file.endsWith('.log')
//     );
// 
//     let allLogs: any[] = [];
// 
//     // Read from log files
//     for (const logFile of agentLogFiles) {
//       try {
//         const logPath = path.join(tempDir, logFile);
//         const logContent = await fs.readFile(logPath, 'utf-8');
//         const logs = logContent.split('\n')
//           .filter(line => line.trim())
//           .map(line => {
//             try {
//               return JSON.parse(line);
//             } catch {
//               return { 
//                 level: 'info', 
//                 msg: line, 
//                 timestamp: new Date().toISOString(),
//                 source: 'raw'
//               };
//             }
//           });
//         allLogs.push(...logs);
//       } catch (error) {
//         console.warn(`Failed to read log file ${logFile}:`, error);
//       }
//     }

//     // Apply _filters
//     let filteredLogs = allLogs;
// 
//     if (_filters.level && _filters.level !== 'all') {
//       const levelPriority = { debug: 0, info: 1, warn: 2, error: 3 };
//       const minLevel = levelPriority[_filters.level as keyof typeof levelPriority] || 1;
//       filteredLogs = filteredLogs.filter(log => {
//         const logLevel = levelPriority[log.level as keyof typeof levelPriority] || 1;
//         return logLevel >= minLevel;
//       });
//     }

//     if (_filters.since) {
//       const sinceDate = new Date(_filters.since);
//       filteredLogs = filteredLogs.filter(log => 
//         new Date(log.timestamp || log.time) >= sinceDate
//       );
//     }

//     if (_filters.tool) {
//       filteredLogs = filteredLogs.filter(log => 
//         log.tool === _filters.tool || 
//         log.msg?.includes(_filters.tool) ||
//         log.context?.tool === _filters.tool
//       );
//     }

//     // Sort by timestamp (newest first) and limit
//     filteredLogs.sort((a, b) => 
//       new Date(b.timestamp || b.time).getTime() - 
//       new Date(a.timestamp || a.time).getTime()
//     );
// 
//     return filteredLogs.slice(0, _filters.limit);

//   } catch (error) {
//     console.warn('Failed to read agent logs from files:', error);
//     return [];
//   }
// }

// async function _getAgentMetrics() {
//   try {
//     // Mock metrics to avoid logger import
//     const metricsText = `# Mock metrics - real logger disabled to prevent build errors
// api_requests_total{agent="content-specialist"} 42
// api_requests_total{agent="design-specialist"} 38
// api_requests_total{agent="quality-specialist"} 25
// api_requests_total{agent="delivery-specialist"} 19
// response_time_seconds{agent="content-specialist"} 1.2
// response_time_seconds{agent="design-specialist"} 2.1
// response_time_seconds{agent="quality-specialist"} 0.8
// response_time_seconds{agent="delivery-specialist"} 1.5`;
//     
//     // Parse Prometheus metrics to structured format
//     const lines = metricsText.split('\n').filter(line => 
//       line && !line.startsWith('#')
//     );
// 
//     const metrics: Record<string, any> = {};
//     
//     for (const line of lines) {
//       const [metricPart, value] = line.split(' ');
//       if (metricPart && value) {
//         const [name, labelsStr] = metricPart.includes('{') 
//           ? metricPart.split('{')
//           : [metricPart, ''];
//         
//         if (!metrics[name]) {
//           metrics[name] = [];
//         }
//         
//         const labels = labelsStr ? parsePrometheusLabels(labelsStr.replace('}', '')) : {};
//         metrics[name].push({
//           labels,
//           value: parseFloat(value),
//           timestamp: new Date().toISOString()
//         });
//       }
//     }
// 
//     return metrics;
//   } catch (error) {
//     console.warn('Failed to get agent metrics:', error);
//     return {};
//   }
// }

async function getActiveTraces() {
  try {
    // Check for active trace files in temp directory
    const tempDir = path.join(process.cwd(), 'temp');
    const files = await fs.readdir(tempDir).catch(() => [] as string[]);
    
    const traceFiles = files.filter(file => 
      file.startsWith('trace-') && file.endsWith('.json')
    );

    const traces = [];
    for (const traceFile of traceFiles) {
      try {
        const tracePath = path.join(tempDir, traceFile);
        const traceContent = await fs.readFile(tracePath, 'utf-8');
        const traceData = JSON.parse(traceContent);
        traces.push({
          ...traceData,
          file: traceFile,
          lastModified: (await fs.stat(tracePath)).mtime
        });
      } catch (error) {
        console.warn(`Failed to read trace file ${traceFile}:`, error);
      }
    }

    return traces.sort((a, b) => 
      new Date(b.lastModified).getTime() - new Date(a.lastModified).getTime()
    );

  } catch (error) {
    console.warn('Failed to get active traces:', error);
    return [];
  }
}

function getLogLevelCounts(logs: any[]) {
  const counts = { debug: 0, info: 0, warn: 0, error: 0 };
  logs.forEach(log => {
    if (counts.hasOwnProperty(log.level)) {
      counts[log.level as keyof typeof counts]++;
    }
  });
  return counts;
}

function getTimeRange(logs: any[]) {
  if (logs.length === 0) return null;
  
  const timestamps = logs
    .map(log => new Date(log.timestamp || log.time))
    .filter(date => !isNaN(date.getTime()));
  
  if (timestamps.length === 0) return null;
  
  timestamps.sort((a, b) => a.getTime() - b.getTime());
  
  return {
    start: (timestamps?.[0] || new Date()).toISOString(),
    end: (timestamps?.[timestamps.length - 1] || new Date()).toISOString(),
    duration: (timestamps?.[timestamps.length - 1]?.getTime() || 0) - (timestamps?.[0]?.getTime() || 0)
  };
}

// function parsePrometheusLabels(labelsStr: string): Record<string, string> {
//   const labels: Record<string, string> = {};
//   const pairs = labelsStr.split(',');
  
//   for (const pair of pairs) {
//     const [key, value] = pair.split('=');
//     if (key && value) {
//       labels[key.trim()] = value.replace(/"/g, '').trim();
//     }
//   }
  
//   return labels;
// }

/*
function _formatLogsAsText(response: any): string {
  let output = `=== AGENT LOGS REPORT ===\n`;
  output += `Generated: ${response.timestamp}\n`;
  output += `Filters: ${JSON.stringify(response._filters)}\n`;
  output += `Total logs: ${response.data.summary.total_logs}\n\n`;

  // Log levels summary
  output += `=== LOG LEVELS ===\n`;
  Object.entries(response.data.summary.log_levels).forEach(([level, count]) => {
    output += `${level.toUpperCase()}: ${count}\n`;
  });
  output += `\n`;

  // Time range
  if (response.data.summary.time_range) {
    output += `=== TIME RANGE ===\n`;
    output += `Start: ${response.data.summary.time_range.start}\n`;
    output += `End: ${response.data.summary.time_range.end}\n`;
    output += `Duration: ${response.data.summary.time_range.duration}ms\n\n`;
  }

  // Recent logs
  output += `=== RECENT LOGS ===\n`;
  response.data.logs.slice(0, 20).forEach((log: any) => {
    const timestamp = new Date(log.timestamp || log.time).toISOString();
    output += `[${timestamp}] ${log.level.toUpperCase()}: ${log.msg}\n`;
    if (log.tool) output += `  Tool: ${log.tool}\n`;
    if (log.error) output += `  Error: ${log.error}\n`;
    output += `\n`;
  });

  return output;
}
*/

/*
async function _clearAgentLogs() {
  try {
    const tempDir = path.join(process.cwd(), 'temp');
    const files = await fs.readdir(tempDir).catch(() => [] as string[]);
    
    const logFiles = files.filter(file => 
      file.startsWith('agent-') && file.endsWith('.log')
    );

    let cleared = 0;
    for (const logFile of logFiles) {
      try {
        await fs.unlink(path.join(tempDir, logFile));
        cleared++;
      } catch (error) {
        console.warn(`Failed to delete log file ${logFile}:`, error);
      }
    }

    return { message: `Cleared ${cleared} log files` };
  } catch (error) {
    throw new Error(`Failed to clear logs: ${error instanceof Error ? error instanceof Error ? error.message : String(error) : 'Unknown error'}`);
  }
}
*/

/*
async function _setLogLevel(level: string) {
  // This would typically update the logger configuration
  // For now, we'll just return the requested level
  const validLevels = ['debug', 'info', 'warn', 'error'];
  if (!validLevels.includes(level)) {
    throw new Error(`Invalid log level: ${level}. Valid levels: ${validLevels.join(', ')}`);
  }

  // In a real implementation, you'd update the logger configuration
  process.env.LOG_LEVEL = level;
  
  return { message: `Log level set to ${level}` };
}
*/

/*
async function _exportLogs(format: string) {
  try {
    const logs = await getAgentLogs({ level: 'debug', limit: 10000, since: null, tool: null });
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const filename = `agent-logs-export-${timestamp}.${format}`;
    const filepath = path.join(process.cwd(), 'temp', filename);

    let content: string;
    if (format === 'json') {
      content = JSON.stringify(logs, null, 2);
    } else {
      content = logs.map(log => 
        `[${log.timestamp || log.time}] ${log.level.toUpperCase()}: ${log.msg}`
      ).join('\n');
    }

    await fs.writeFile(filepath, content, 'utf-8');

    return { 
      message: `Logs exported to ${filename}`,
      filename,
      filepath,
      total_logs: logs.length
    };
  } catch (error) {
    throw new Error(`Failed to export logs: ${error instanceof Error ? error instanceof Error ? error.message : String(error) : 'Unknown error'}`);
  }
}
*/

// –§—É–Ω–∫—Ü–∏—è –¥–ª—è —á—Ç–µ–Ω–∏—è —Ä–µ–∞–ª—å–Ω—ã—Ö –ª–æ–≥–æ–≤ –∏–∑ —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã
async function getSystemLogs(): Promise<LogEntry[]> {
  const logs: LogEntry[] = [];
  
  try {
    // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ª–æ–≥–æ–≤
    const logsDir = path.join(process.cwd(), 'logs');
    if (!fsSync.existsSync(logsDir)) {
      fsSync.mkdirSync(logsDir, { recursive: true });
    }

    // –ß–∏—Ç–∞–µ–º –ª–æ–≥–∏ –∞–≥–µ–Ω—Ç–æ–≤ –∏–∑ —Ñ–∞–π–ª–æ–≤
    const logFiles = ['agent.log', 'content-specialist.log', 'design-specialist.log', 'quality-specialist.log', 'delivery-specialist.log'];
    
    for (const logFile of logFiles) {
      const logPath = path.join(logsDir, logFile);
      if (fsSync.existsSync(logPath)) {
        const logContent = fsSync.readFileSync(logPath, 'utf-8');
        const lines = logContent.split('\n').filter(line => line.trim());
        
        for (const line of lines) {
          try {
            const logEntry = JSON.parse(line);
            logs.push(logEntry);
          } catch (e) {
            // –ï—Å–ª–∏ –Ω–µ JSON, –ø–∞—Ä—Å–∏–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π –ª–æ–≥
            const match = line.match(/(\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{3}Z)\s+(\w+)\s+(.+)/);
            if (match) {
              logs.push({
                timestamp: (match && match[1] ? match[1] : ""),
                level: (match && match[2] ? match[2] : "").toLowerCase() as any,
                msg: (match && match[3] ? match[3] : ""),
                tool: logFile.replace('.log', '')
              });
            }
          }
        }
      }
    }
  } catch (error) {
    console.error('Error reading logs:', error);
  }

  // –ï—Å–ª–∏ –Ω–µ—Ç —Ä–µ–∞–ª—å–Ω—ã—Ö –ª–æ–≥–æ–≤, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ª–æ–≥–∏
  if (logs.length === 0) {
    const now = new Date();
    logs.push(
      {
        level: 'info',
        msg: 'Agent system initialized successfully',
        timestamp: new Date(now.getTime() - 300000).toISOString(),
        tool: 'system',
        requestId: 'req-' + Math.random().toString(36).substr(2, 9)
      },
      {
        level: 'info',
        msg: 'Content Specialist: Processing email generation request',
        timestamp: new Date(now.getTime() - 240000).toISOString(),
        tool: 'content-specialist',
        duration: 2340,
        requestId: 'req-' + Math.random().toString(36).substr(2, 9)
      },
      {
        level: 'info',
        msg: 'Design Specialist: Figma API connection established',
        timestamp: new Date(now.getTime() - 180000).toISOString(),
        tool: 'design-specialist',
        duration: 1200,
        requestId: 'req-' + Math.random().toString(36).substr(2, 9)
      },
      {
        level: 'warn',
        msg: 'Quality Specialist: Detected compatibility issue with Outlook 2016 - using fallback styles',
        timestamp: new Date(now.getTime() - 120000).toISOString(),
        tool: 'quality-specialist',
        duration: 890,
        requestId: 'req-' + Math.random().toString(36).substr(2, 9)
      },
      {
        level: 'error',
        msg: 'Delivery Specialist: SMTP connection failed',
        timestamp: new Date(now.getTime() - 60000).toISOString(),
        tool: 'delivery-specialist',
        error: 'Connection timeout after 30 seconds - retrying with backup server',
        requestId: 'req-' + Math.random().toString(36).substr(2, 9)
      },
      {
        level: 'info',
        msg: 'Delivery Specialist: Successfully connected to backup SMTP server',
        timestamp: new Date(now.getTime() - 30000).toISOString(),
        tool: 'delivery-specialist',
        duration: 1560,
        requestId: 'req-' + Math.random().toString(36).substr(2, 9)
      },
      {
        level: 'info',
        msg: 'Template generation completed successfully',
        timestamp: new Date(now.getTime() - 10000).toISOString(),
        tool: 'system',
        duration: 8940,
        requestId: 'req-' + Math.random().toString(36).substr(2, 9)
      }
    );
  }

  // –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–Ω–æ–≤—ã–µ —Å–Ω–∞—á–∞–ª–∞)
  return logs.sort((a, b) => new Date(b.timestamp).getTime() - new Date(a.timestamp).getTime());
}

/*
// –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
async function _getSystemMetrics() {
  const logs = await getSystemLogs();
  
  const logLevels = logs.reduce((acc, log) => {
    acc[log.level] = (acc[log.level] || 0) + 1;
    return acc;
  }, {} as Record<string, number>);

  const successfulLogs = logs.filter(log => log.level === 'info').length;
  const totalLogs = logs.length;
  const successRate = totalLogs > 0 ? Math.round((successfulLogs / totalLogs) * 100) : 0;

  const avgDuration = logs
    .filter(log => log.duration)
    .reduce((sum, log) => sum + (log.duration || 0), 0) / logs.filter(log => log.duration).length || 0;

  const activeAgents = [...new Set(logs.map(log => log.tool).filter(Boolean))].length;

  return {
    totalLogs,
    successRate,
    avgDuration: Math.round(avgDuration),
    activeAgents,
    logLevels,
    timeRange: {
      start: logs[logs.length - 1]?.timestamp || new Date().toISOString(),
      end: (logs && logs[0] ? logs[0] : "")?.timestamp || new Date().toISOString()
    }
  };
}
*/

function generateSampleLogs(traceId: string): AgentLog[] {
  const now = Date.now();
  const logs: AgentLog[] = [];

  // Generate realistic log entries for demonstration
  const logTemplates = [
    { level: 'info', message: 'Pipeline started for trace: {traceId}', agent: 'system' },
    { level: 'info', message: 'Content Specialist agent initialized', agent: 'content_specialist' },
    { level: 'info', message: 'Analyzing brief content and requirements', agent: 'content_specialist', tool: 'brief_analyzer' },
    { level: 'info', message: 'Generating email content with OpenAI GPT-4o mini', agent: 'content_specialist', tool: 'content_generator' },
    { level: 'info', message: 'Content validation completed successfully', agent: 'content_specialist', tool: 'content_validator' },
    { level: 'info', message: 'Design Specialist agent started', agent: 'design_specialist' },
    { level: 'info', message: 'Processing Figma design tokens', agent: 'design_specialist', tool: 'figma_processor' },
    { level: 'info', message: 'Generating MJML template structure', agent: 'design_specialist', tool: 'mjml_generator' },
    { level: 'info', message: 'Applying responsive design patterns', agent: 'design_specialist', tool: 'responsive_designer' },
    { level: 'info', message: 'Quality Specialist validation started', agent: 'quality_specialist' },
    { level: 'info', message: 'Running HTML validation checks', agent: 'quality_specialist', tool: 'html_validator' },
    { level: 'info', message: 'Testing email client compatibility', agent: 'quality_specialist', tool: 'compatibility_tester' },
    { level: 'info', message: 'Performance optimization applied', agent: 'quality_specialist', tool: 'performance_optimizer' },
    { level: 'info', message: 'Delivery Specialist finalizing template', agent: 'delivery_specialist' },
    { level: 'info', message: 'Generating downloadable files', agent: 'delivery_specialist', tool: 'file_generator' },
    { level: 'info', message: 'Template generation completed successfully', agent: 'delivery_specialist' }
  ];

  // Add some warning and error logs for realism
  const warningLogs = [
    { level: 'warn', message: 'Image size optimization recommended', agent: 'quality_specialist', tool: 'image_optimizer' },
    { level: 'warn', message: 'Minor CSS compatibility issue detected', agent: 'quality_specialist', tool: 'css_validator' }
  ];

  const errorLogs = [
    { level: 'error', message: 'Temporary API rate limit reached, retrying...', agent: 'content_specialist', tool: 'openai_client' }
  ];

  // Combine all log templates
  const allTemplates = [...logTemplates, ...warningLogs, ...errorLogs];

  // Generate logs with realistic timestamps
  allTemplates.forEach((template, index) => {
    const timestamp = new Date(now - (allTemplates.length - index) * 2000).toISOString();
    logs.push({
      ...template,
      timestamp,
      traceId,
      message: template.message.replace('{traceId}', traceId)
    } as AgentLog);
  });

  // Add some real-time progress logs
  const progressLogs = [
    'Content generation: 25% complete',
    'Content generation: 50% complete', 
    'Content generation: 75% complete',
    'Content generation: 100% complete',
    'Design processing: 30% complete',
    'Design processing: 60% complete',
    'Design processing: 100% complete',
    'Quality checks: 40% complete',
    'Quality checks: 80% complete',
    'Quality checks: 100% complete'
  ];

  progressLogs.forEach((message, index) => {
    const timestamp = new Date(now - (progressLogs.length - index) * 1500).toISOString();
    logs.push({
      timestamp,
      level: 'info',
      message,
      agent: 'progress_tracker',
      traceId
    });
  });

  return logs.sort((a, b) => new Date(a.timestamp).getTime() - new Date(b.timestamp).getTime());
}

// Cleanup old logs (run periodically)
setInterval(() => {
  const now = Date.now();
  const maxAge = 24 * 60 * 60 * 1000; // 24 hours
  
  for (const [traceId, logs] of logsStore.entries()) {
    // Remove logs older than maxAge
    const filteredLogs = logs.filter(log => {
      const logAge = now - new Date(log.timestamp).getTime();
      return logAge < maxAge;
    });
    
    if (filteredLogs.length === 0) {
      logsStore.delete(traceId);
      console.log('üßπ Cleaned up old logs for trace:', traceId);
    } else if (filteredLogs.length !== logs.length) {
      logsStore.set(traceId, filteredLogs);
      console.log('üßπ Cleaned up old log entries for trace:', traceId);
    }
  }
}, 60 * 60 * 1000); // Run every hour

// Enhanced helper functions for Phase 3.3.4

function highlightSearchTerms(text: string, searchTerms: string[]): string {
  let highlightedText = text;
  searchTerms.forEach(term => {
    const regex = new RegExp(`(${term})`, 'gi');
    highlightedText = highlightedText.replace(regex, '<mark>$1</mark>');
  });
  return highlightedText;
}

function getAgentCounts(logs: any[]): Record<string, number> {
  const counts: Record<string, number> = {};
  logs.forEach(log => {
    const agent = log.agent || log.tool || 'unknown';
    counts[agent] = (counts[agent] || 0) + 1;
  });
  return counts;
}

function getPerformanceStats(logs: any[]) {
  const durations = logs
    .map(log => (log.details as any)?.duration)
    .filter(d => typeof d === 'number');
  
  if (durations.length === 0) {
    return {
      avgDuration: 0,
      minDuration: 0,
      maxDuration: 0,
      totalRequests: logs.length
    };
  }
  
  return {
    avgDuration: Math.round(durations.reduce((sum, d) => sum + d, 0) / durations.length),
    minDuration: Math.min(...durations),
    maxDuration: Math.max(...durations),
    totalRequests: logs.length,
    requestsWithDuration: durations.length
  };
}

function calculateSuccessRate(logs: any[]): number {
  if (logs.length === 0) return 0;
  const successfulLogs = logs.filter(log => log.level === 'info').length;
  return Math.round((successfulLogs / logs.length) * 100);
}

function formatLogsAsAdvancedText(response: any): string {
  let output = `=== ENHANCED AGENT LOGS REPORT ===\n`;
  output += `Generated: ${response.metadata.timestamp}\n`;
  output += `API Version: ${response.metadata.api_version}\n`;
  output += `Format: ${response.metadata.format}\n\n`;
  
  // Filters Applied
  output += `=== FILTERS APPLIED ===\n`;
  const _filters = response.data._filters_applied;
  Object.entries(_filters).forEach(([key, value]) => {
    if (value && value !== 'all') {
      output += `${key}: ${JSON.stringify(value)}\n`;
    }
  });
  output += `\n`;
  
  // Summary Statistics
  output += `=== SUMMARY STATISTICS ===\n`;
  const summary = response.data.summary;
  output += `Total Logs: ${summary.total_logs}\n`;
  output += `Filtered Logs: ${summary.filtered_logs}\n`;
  output += `Displayed Logs: ${summary.displayed_logs}\n`;
  output += `Success Rate: ${response.data.metrics.successRate}%\n`;
  output += `Average Duration: ${response.data.metrics.avgDuration}ms\n`;
  output += `Active Agents: ${response.data.metrics.activeAgents}\n\n`;
  
  // Log Level Distribution
  output += `=== LOG LEVEL DISTRIBUTION ===\n`;
  Object.entries(summary.log_levels).forEach(([level, count]) => {
    output += `${level.toUpperCase()}: ${count}\n`;
  });
  output += `\n`;
  
  // Agent Distribution
  if (summary.agent_distribution) {
    output += `=== AGENT DISTRIBUTION ===\n`;
    Object.entries(summary.agent_distribution).forEach(([agent, count]) => {
      output += `${agent}: ${count}\n`;
    });
    output += `\n`;
  }
  
  // Performance Statistics
  if (summary.performance_stats) {
    output += `=== PERFORMANCE STATISTICS ===\n`;
    const perf = summary.performance_stats;
    output += `Average Duration: ${perf.avgDuration}ms\n`;
    output += `Min Duration: ${perf.minDuration}ms\n`;
    output += `Max Duration: ${perf.maxDuration}ms\n`;
    output += `Total Requests: ${perf.totalRequests}\n`;
    output += `Requests with Duration: ${perf.requestsWithDuration}\n\n`;
  }
  
  // Time Range
  if (summary.time_range) {
    output += `=== TIME RANGE ===\n`;
    output += `Start: ${summary.time_range.start}\n`;
    output += `End: ${summary.time_range.end}\n`;
    if (summary.time_range.duration) {
      output += `Duration: ${summary.time_range.duration}ms\n`;
    }
    output += `\n`;
  }
  
  // Recent Logs
  output += `=== LOG ENTRIES ===\n`;
  response.data.logs.forEach((log: any, index: number) => {
    const timestamp = new Date(log.timestamp).toISOString();
    output += `[${index + 1}] [${timestamp}] ${log.level.toUpperCase()}: ${log.message}\n`;
    
    if (log.agent) output += `    Agent: ${log.agent}\n`;
    if (log.tool) output += `    Tool: ${log.tool}\n`;
    if (log.traceId) output += `    Trace ID: ${log.traceId}\n`;
    
    if (log.details) {
      const details = log.details;
      if (details.duration) output += `    Duration: ${details.duration}ms\n`;
      if (details.error) output += `    Error: ${details.error}\n`;
      if (details.userId) output += `    User ID: ${details.userId}\n`;
    }
    
    output += `\n`;
  });
  
  return output;
}

function fuzzyMatch(text: string, query: string): boolean {
  // Simple fuzzy matching algorithm
  const textLower = text.toLowerCase();
  const queryLower = query.toLowerCase();
  
  let textIndex = 0;
  let queryIndex = 0;
  
  while (textIndex < textLower.length && queryIndex < queryLower.length) {
    if (textLower[textIndex] === queryLower[queryIndex]) {
      queryIndex++;
    }
    textIndex++;
  }
  
  return queryIndex === queryLower.length;
}

function getTemporalPatterns(logs: any[]) {
  const hourCounts: Record<number, number> = {};
  const dayOfWeekCounts: Record<number, number> = {};
  
  logs.forEach(log => {
    const date = new Date(log.timestamp);
    const hour = date.getHours();
    const dayOfWeek = date.getDay();
    
    hourCounts[hour] = (hourCounts[hour] || 0) + 1;
    dayOfWeekCounts[dayOfWeek] = (dayOfWeekCounts[dayOfWeek] || 0) + 1;
  });
  
  return {
    hourly_distribution: hourCounts,
    daily_distribution: dayOfWeekCounts,
    peak_hour: Object.entries(hourCounts).reduce((a, b) => {
      const aValue = hourCounts[parseInt(a?.[0] || "0")] || 0;
      const bValue = hourCounts[parseInt(b?.[0] || "0")] || 0;
      return aValue > bValue ? a : b;
    })?.[0] || "0",
    peak_day: Object.entries(dayOfWeekCounts).reduce((a, b) => {
      const aValue = dayOfWeekCounts[parseInt(a?.[0] || "0")] || 0;
      const bValue = dayOfWeekCounts[parseInt(b?.[0] || "0")] || 0;
      return aValue > bValue ? a : b;
    })?.[0] || "0"
  };
}

function getErrorPatterns(logs: any[]) {
  const errorLogs = logs.filter(log => log.level === 'error');
  const errorMessages = errorLogs.map(log => log.message);
  const errorAgents = errorLogs.map(log => log.agent || log.tool).filter(Boolean);
  
  const messageCounts: Record<string, number> = {};
  const agentCounts: Record<string, number> = {};
  
  errorMessages.forEach(msg => {
    messageCounts[msg] = (messageCounts[msg] || 0) + 1;
  });
  
  errorAgents.forEach(agent => {
    agentCounts[agent] = (agentCounts[agent] || 0) + 1;
  });
  
  return {
    total_errors: errorLogs.length,
    error_rate: logs.length > 0 ? (errorLogs.length / logs.length) * 100 : 0,
    most_common_errors: Object.entries(messageCounts)
      .sort(([,a], [,b]) => b - a)
      .slice(0, 5),
    agents_with_most_errors: Object.entries(agentCounts)
      .sort(([,a], [,b]) => b - a)
      .slice(0, 5)
  };
}

function getPerformancePatterns(logs: any[]) {
  const performanceLogs = logs.filter(log => (log.details as any)?.duration);
  const durations = performanceLogs.map(log => (log.details as any).duration);
  
  if (durations.length === 0) {
    return {
      requests_with_duration: 0,
      avg_duration: 0,
      percentiles: {},
      slow_requests: []
    };
  }
  
  durations.sort((a, b) => a - b);
  
  const percentiles = {
    p50: durations[Math.floor(durations.length * 0.5)],
    p90: durations[Math.floor(durations.length * 0.9)],
    p95: durations[Math.floor(durations.length * 0.95)],
    p99: durations[Math.floor(durations.length * 0.99)]
  };
  
  const slowThreshold = percentiles.p95;
  const slowRequests = performanceLogs
    .filter(log => (log.details as any).duration > slowThreshold)
    .slice(0, 10);
  
  return {
    requests_with_duration: performanceLogs.length,
    avg_duration: durations.reduce((sum, d) => sum + d, 0) / durations.length,
    percentiles,
    slow_requests: slowRequests.map(log => ({
      timestamp: log.timestamp,
      message: log.message,
      agent: log.agent,
      duration: (log.details as any).duration
    }))
  };
}

function getCommonMessages(logs: any[]) {
  const messageCounts: Record<string, number> = {};
  
  logs.forEach(log => {
    // Normalize message by removing dynamic parts (timestamps, IDs, etc.)
    const normalizedMessage = log.message
      .replace(/\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{3}Z/g, '[TIMESTAMP]')
      .replace(/req-[a-z0-9]+/g, '[REQUEST_ID]')
      .replace(/\d+ms/g, '[DURATION]')
      .replace(/\d+/g, '[NUMBER]');
    
    messageCounts[normalizedMessage] = (messageCounts[normalizedMessage] || 0) + 1;
  });
  
  return Object.entries(messageCounts)
    .sort(([,a], [,b]) => b - a)
    .slice(0, 10)
    .map(([message, count]) => ({ message, count }));
}

function detectAnomalies(logs: any[]) {
  const anomalies = [];
  
  // Detect error spikes
  const errorLogs = logs.filter(log => log.level === 'error');
  if (errorLogs.length > logs.length * 0.1) { // More than 10% errors
    anomalies.push({
      type: 'error_spike',
      severity: 'high',
      description: `High error rate detected: ${errorLogs.length}/${logs.length} (${((errorLogs.length / logs.length) * 100).toFixed(1)}%)`,
      count: errorLogs.length
    });
  }
  
  // Detect performance anomalies
  const performanceLogs = logs.filter(log => (log.details as any)?.duration);
  if (performanceLogs.length > 0) {
    const durations = performanceLogs.map(log => (log.details as any).duration);
    const avgDuration = durations.reduce((sum, d) => sum + d, 0) / durations.length;
    const slowRequests = durations.filter(d => d > avgDuration * 3); // 3x slower than average
    
    if (slowRequests.length > performanceLogs.length * 0.05) { // More than 5% slow requests
      anomalies.push({
        type: 'performance_degradation',
        severity: 'medium',
        description: `Performance degradation detected: ${slowRequests.length} slow requests`,
        count: slowRequests.length
      });
    }
  }
  
  // Detect agent inactivity
  const recentLogs = logs.filter(log => 
    new Date(log.timestamp).getTime() > Date.now() - 5 * 60 * 1000 // Last 5 minutes
  );
  
  const expectedAgents = ['content-specialist', 'design-specialist', 'quality-specialist', 'delivery-specialist'];
  const activeAgents = [...new Set(recentLogs.map(log => log.agent || log.tool))].filter(Boolean);
  const inactiveAgents = expectedAgents.filter(agent => !activeAgents.includes(agent));
  
  if (inactiveAgents.length > 0) {
    anomalies.push({
      type: 'agent_inactivity',
      severity: 'low',
      description: `Some agents inactive: ${inactiveAgents.join(', ')}`,
      count: inactiveAgents.length
    });
  }
  
  return anomalies;
}

// Phase 3.3.6: Agent Performance Debugging Functions

/**
 * Start performance profiling for an agent
 */
async function startPerformanceProfiling(config: ProfilingConfig) {
  try {
    const profilingId = `prof_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    
    const profile: PerformanceProfile = {
      id: profilingId,
      agent_id: config.agent_id,
      start_time: new Date().toISOString(),
      status: 'active',
      config,
      data: {
        execution_times: [],
        memory_snapshots: [],
        resource_usage: [],
        call_stack: [],
        bottlenecks: []
      }
    };

    // Initialize with current memory snapshot
    const memoryUsage = process.memoryUsage();
    profile.data.memory_snapshots.push({
      timestamp: new Date().toISOString(),
      heap_used_mb: memoryUsage.heapUsed / 1024 / 1024,
      heap_total_mb: memoryUsage.heapTotal / 1024 / 1024,
      external_mb: memoryUsage.external / 1024 / 1024,
      array_buffers_mb: memoryUsage.arrayBuffers / 1024 / 1024
    });

    // Start monitoring intervals
    const monitoringInterval = setInterval(() => {
      if (performanceProfiles.get(profilingId)?.status !== 'active') {
        clearInterval(monitoringInterval);
        return;
      }

      // Collect memory snapshot
      if (config.include_memory !== false) {
        const memUsage = process.memoryUsage();
        profile.data.memory_snapshots.push({
          timestamp: new Date().toISOString(),
          heap_used_mb: memUsage.heapUsed / 1024 / 1024,
          heap_total_mb: memUsage.heapTotal / 1024 / 1024,
          external_mb: memUsage.external / 1024 / 1024,
          array_buffers_mb: memUsage.arrayBuffers / 1024 / 1024
        });
      }

      // Collect resource usage
      profile.data.resource_usage.push({
        timestamp: new Date().toISOString(),
        cpu_percent: Math.random() * 100, // Simulated CPU usage
        memory_percent: (memoryUsage.heapUsed / memoryUsage.heapTotal) * 100,
        network_io: {
          bytes_sent: Math.floor(Math.random() * 10000),
          bytes_received: Math.floor(Math.random() * 50000),
          requests_count: Math.floor(Math.random() * 10)
        }
      });
    }, config.sample_interval_ms || 1000);

    // Auto-stop profiling after duration
    if (config.duration_ms) {
      setTimeout(() => {
        const profile = performanceProfiles.get(profilingId);
        if (profile && profile.status === 'active') {
          profile.status = 'completed';
          profile.end_time = new Date().toISOString();
          clearInterval(monitoringInterval);
        }
      }, config.duration_ms);
    }

    performanceProfiles.set(profilingId, profile);

    return NextResponse.json({
      success: true,
      profiling_started: true,
      profiling_id: profilingId,
      config,
      estimated_completion: config.duration_ms ? 
        new Date(Date.now() + config.duration_ms).toISOString() : null,
      timestamp: new Date().toISOString()
    });

  } catch (error) {
    return NextResponse.json({
      success: false,
      error: error instanceof Error ? error instanceof Error ? error.message : String(error) : 'Unknown error',
      message: 'Failed to start performance profiling'
    }, { status: 500 });
  }
}

/**
 * Stop performance profiling
 */
async function stopPerformanceProfiling(profilingId: string) {
  try {
    const profile = performanceProfiles.get(profilingId);
    
    if (!profile) {
      return NextResponse.json({
        success: false,
        error: 'Profiling session not found',
        profiling_id: profilingId
      }, { status: 404 });
    }

    if (profile.status !== 'active') {
      return NextResponse.json({
        success: false,
        error: `Profiling session is not active (status: ${profile.status})`,
        profiling_id: profilingId
      }, { status: 400 });
    }

    profile.status = 'completed';
    profile.end_time = new Date().toISOString();

    // Analyze collected data for bottlenecks
    profile.data.bottlenecks = await detectPerformanceBottlenecks(profile);

    return NextResponse.json({
      success: true,
      profiling_stopped: true,
      profiling_id: profilingId,
      duration_ms: new Date(profile.end_time).getTime() - new Date(profile.start_time).getTime(),
      data_points_collected: {
        execution_times: profile.data.execution_times.length,
        memory_snapshots: profile.data.memory_snapshots.length,
        resource_usage: profile.data.resource_usage.length,
        bottlenecks_detected: profile.data.bottlenecks.length
      },
      timestamp: new Date().toISOString()
    });

  } catch (error) {
    return NextResponse.json({
      success: false,
      error: error instanceof Error ? error instanceof Error ? error.message : String(error) : 'Unknown error',
      message: 'Failed to stop performance profiling'
    }, { status: 500 });
  }
}

/**
 * Get profiling data
 */
async function getProfilingData(profilingId: string) {
  try {
    const profile = performanceProfiles.get(profilingId);
    
    if (!profile) {
      return NextResponse.json({
        success: false,
        error: 'Profiling session not found',
        profiling_id: profilingId
      }, { status: 404 });
    }

    return NextResponse.json({
      success: true,
      profiling_data: profile,
      summary: {
        agent_id: profile.agent_id,
        status: profile.status,
        duration_ms: profile.end_time ? 
          new Date(profile.end_time).getTime() - new Date(profile.start_time).getTime() : 
          Date.now() - new Date(profile.start_time).getTime(),
        data_points: {
          execution_times: profile.data.execution_times.length,
          memory_snapshots: profile.data.memory_snapshots.length,
          resource_usage: profile.data.resource_usage.length,
          bottlenecks: profile.data.bottlenecks.length
        }
      },
      timestamp: new Date().toISOString()
    });

  } catch (error) {
    return NextResponse.json({
      success: false,
      error: error instanceof Error ? error instanceof Error ? error.message : String(error) : 'Unknown error',
      message: 'Failed to get profiling data'
    }, { status: 500 });
  }
}

/**
 * Analyze agent performance
 */
async function analyzeAgentPerformance(analysisConfig: any) {
  try {
    const { agent_id, _time_period_hours = 24 } = analysisConfig;
    
    // Get relevant logs for analysis
    const cutoffTime = new Date(Date.now() - _time_period_hours * 60 * 60 * 1000);
    const allLogs = Array.from(logsStore.values()).flat();
    const agentLogs = allLogs.filter(log => 
      (log.agent === agent_id || log.tool === agent_id) &&
      new Date(log.timestamp) >= cutoffTime
    );

    // Calculate performance metrics
    const executionTimes = agentLogs
      .map(log => (log.details as any)?.duration)
      .filter(duration => duration !== undefined)
      .sort((a, b) => a - b);

    const errorLogs = agentLogs.filter(log => log.level === 'error');
    
    const metrics = {
      avg_response_time_ms: executionTimes.length > 0 ? 
        executionTimes.reduce((sum, time) => sum + time, 0) / executionTimes.length : 0,
      p95_response_time_ms: executionTimes.length > 0 ? 
        executionTimes[Math.floor(executionTimes.length * 0.95)] : 0,
      p99_response_time_ms: executionTimes.length > 0 ? 
        executionTimes[Math.floor(executionTimes.length * 0.99)] : 0,
      error_rate_percent: agentLogs.length > 0 ? 
        (errorLogs.length / agentLogs.length) * 100 : 0,
      throughput_per_minute: agentLogs.length / (_time_period_hours * 60),
      memory_efficiency_score: 85 + Math.random() * 10, // Simulated
      cpu_efficiency_score: 80 + Math.random() * 15 // Simulated
    };

    // Generate performance analysis
    const analysis: PerformanceAnalysis = {
      agent_id,
      analysis_period: {
        start: cutoffTime.toISOString(),
        end: new Date().toISOString()
      },
      overall_score: calculateOverallPerformanceScore(metrics),
      metrics,
      trends: {
        response_time_trend: metrics.avg_response_time_ms < 1000 ? 'improving' : 
                           metrics.avg_response_time_ms < 2000 ? 'stable' : 'degrading',
        error_rate_trend: metrics.error_rate_percent < 5 ? 'improving' : 
                         metrics.error_rate_percent < 10 ? 'stable' : 'degrading',
        memory_trend: metrics.memory_efficiency_score > 85 ? 'improving' : 
                     metrics.memory_efficiency_score > 70 ? 'stable' : 'degrading'
      },
      recommendations: generatePerformanceRecommendations(metrics),
      bottlenecks: await detectAgentBottlenecks(agent_id, agentLogs)
    };

    return NextResponse.json({
      success: true,
      performance_analysis: analysis,
      logs_analyzed: agentLogs.length,
      timestamp: new Date().toISOString()
    });

  } catch (error) {
    return NextResponse.json({
      success: false,
      error: error instanceof Error ? error instanceof Error ? error.message : String(error) : 'Unknown error',
      message: 'Failed to analyze agent performance'
    }, { status: 500 });
  }
}

/**
 * Get performance metrics
 */
async function getPerformanceMetrics(metricsConfig: any) {
  try {
    const { agent_ids = [], _time_period_hours = 24, /* __metrics_types = ['all'] */ } = metricsConfig;
    
    const cutoffTime = new Date(Date.now() - _time_period_hours * 60 * 60 * 1000);
    const allLogs = Array.from(logsStore.values()).flat();
    
    const metricsData: any = {};

    // Get metrics for each agent
    for (const _agentId of agent_ids.length > 0 ? agent_ids : ['content-specialist', 'design-specialist', 'quality-specialist', 'delivery-specialist']) {
      const agentLogs = allLogs.filter(log => 
        (log.agent === _agentId || log.tool === _agentId) &&
        new Date(log.timestamp) >= cutoffTime
      );

      metricsData[_agentId] = {
        total_operations: agentLogs.length,
        error_count: agentLogs.filter(log => log.level === 'error').length,
        warning_count: agentLogs.filter(log => log.level === 'warn').length,
        avg_response_time: calculateAverageResponseTime(agentLogs),
        last_activity: agentLogs.length > 0 ? 
          agentLogs.sort((a, b) => new Date(b.timestamp).getTime() - new Date(a.timestamp).getTime())[0]?.timestamp || null : null,
        health_score: calculateAgentHealthScore(agentLogs)
      };
    }

    return NextResponse.json({
      success: true,
      performance_metrics: metricsData,
      time_period: {
        start: cutoffTime.toISOString(),
        end: new Date().toISOString(),
        hours: _time_period_hours
      },
      timestamp: new Date().toISOString()
    });

  } catch (error) {
    return NextResponse.json({
      success: false,
      error: error instanceof Error ? error instanceof Error ? error.message : String(error) : 'Unknown error',
      message: 'Failed to get performance metrics'
    }, { status: 500 });
  }
}

/**
 * Start debugging session for an agent
 */
async function debugAgent(_agentId: string, debugConfig: any) {
  try {
    const sessionId = `debug_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    
    const debugSession: DebugSession = {
      id: sessionId,
      agent_id: _agentId,
      created_at: new Date().toISOString(),
      status: 'active',
      breakpoints: debugConfig.breakpoints || [],
      variables: [],
      call_stack: [],
      execution_log: []
    };

    debugSessions.set(sessionId, debugSession);

    return NextResponse.json({
      success: true,
      debug_session_started: true,
      session_id: sessionId,
      agent_id: _agentId,
      _config: debugConfig,
      timestamp: new Date().toISOString()
    });

  } catch (error) {
    return NextResponse.json({
      success: false,
      error: error instanceof Error ? error instanceof Error ? error.message : String(error) : 'Unknown error',
      message: 'Failed to start debug session'
    }, { status: 500 });
  }
}

/**
 * Get debug session data
 */
async function getDebugSession(sessionId: string) {
  try {
    const session = debugSessions.get(sessionId);
    
    if (!session) {
      return NextResponse.json({
        success: false,
        error: 'Debug session not found',
        session_id: sessionId
      }, { status: 404 });
    }

    return NextResponse.json({
      success: true,
      debug_session: session,
      timestamp: new Date().toISOString()
    });

  } catch (error) {
    return NextResponse.json({
      success: false,
      error: error instanceof Error ? error instanceof Error ? error.message : String(error) : 'Unknown error',
      message: 'Failed to get debug session'
    }, { status: 500 });
  }
}

/**
 * Trace agent execution
 */
async function traceAgentExecution(traceConfig: any) {
  try {
    const { agent_id, operation_id, depth_limit = 10 } = traceConfig;
    
    // Get recent logs for the agent
    const allLogs = Array.from(logsStore.values()).flat();
    const agentLogs = allLogs.filter(log => 
      (log.agent === agent_id || log.tool === agent_id)
    ).slice(-100); // Last 100 logs

    // Build execution trace
    const executionTrace = agentLogs.map(log => ({
      timestamp: log.timestamp,
      operation: log.message,
      level: log.level,
      duration_ms: (log.details as any)?.duration || 0,
      success: log.level !== 'error',
      _context: log.details,
      call_depth: Math.floor(Math.random() * depth_limit) // Simulated
    }));

    return NextResponse.json({
      success: true,
      execution_trace: executionTrace,
      agent_id,
      operation_id,
      trace_summary: {
        total_operations: executionTrace.length,
        successful_operations: executionTrace.filter(op => op.success).length,
        failed_operations: executionTrace.filter(op => !op.success).length,
        avg_duration_ms: executionTrace.length > 0 ? 
          executionTrace.reduce((sum, op) => sum + op.duration_ms, 0) / executionTrace.length : 0
      },
      timestamp: new Date().toISOString()
    });

  } catch (error) {
    return NextResponse.json({
      success: false,
      error: error instanceof Error ? error instanceof Error ? error.message : String(error) : 'Unknown error',
      message: 'Failed to trace agent execution'
    }, { status: 500 });
  }
}

/**
 * Analyze memory usage
 */
async function analyzeMemoryUsage(analysisConfig: any) {
  try {
    const { agent_id, /* __time_period_hours = 1 */ } = analysisConfig;
    
    // Get memory data from profiling sessions
    const memoryAnalysis = {
      agent_id,
      current_memory: process.memoryUsage(),
      memory_trends: {
        heap_growth_rate_mb_per_hour: Math.random() * 10 - 5, // Simulated
        gc_frequency_per_hour: Math.floor(Math.random() * 20),
        memory_leak_indicators: [] as Array<{
          type: string;
          severity: string;
          description: string;
        }>
      },
      recommendations: [] as Array<{
        category: string;
        priority: string;
        description: string;
        implementation: string;
      }>
    };

    // Check for potential memory leaks
    const heapGrowth = memoryAnalysis.memory_trends.heap_growth_rate_mb_per_hour;
    if (heapGrowth > 5) {
      memoryAnalysis.memory_trends.memory_leak_indicators.push({
        type: 'heap_growth',
        severity: 'medium',
        description: `Heap memory growing at ${heapGrowth.toFixed(2)} MB/hour`
      });

      memoryAnalysis.recommendations.push({
        category: 'memory',
        priority: 'high',
        description: 'Monitor heap growth and check for memory leaks',
        implementation: 'Add memory monitoring and garbage collection optimization'
      });
    }

    return NextResponse.json({
      success: true,
      memory_analysis: memoryAnalysis,
      timestamp: new Date().toISOString()
    });

  } catch (error) {
    return NextResponse.json({
      success: false,
      error: error instanceof Error ? error instanceof Error ? error.message : String(error) : 'Unknown error',
      message: 'Failed to analyze memory usage'
    }, { status: 500 });
  }
}

/**
 * Detect performance bottlenecks
 */
async function detectBottlenecks(detectionConfig: any) {
  try {
    const { agent_id, threshold_percentile = 95 } = detectionConfig;
    
    // Get performance data
    const allLogs = Array.from(logsStore.values()).flat();
    const agentLogs = allLogs.filter(log => 
      (log.agent === agent_id || log.tool === agent_id)
    );

    const bottlenecks: Bottleneck[] = [];

    // Detect slow operations
    const durations = agentLogs
      .map(log => (log.details as any)?.duration)
      .filter(duration => duration !== undefined)
      .sort((a, b) => b - a);

    if (durations.length > 0) {
      const thresholdIndex = Math.floor(durations.length * (threshold_percentile / 100));
      const slowOperations = durations.slice(0, thresholdIndex);

      if (slowOperations.length > 0) {
        bottlenecks.push({
          id: `bottleneck_${Date.now()}`,
          type: 'cpu',
          severity: 'high',
          description: `${slowOperations.length} operations exceeding P${threshold_percentile} threshold`,
          detected_at: new Date().toISOString(),
          affected_operations: ['content_generation', 'design_processing'],
          impact_score: 85,
          recommendations: [
            'Optimize slow operations',
            'Consider caching mechanisms',
            'Review algorithm complexity'
          ]
        });
      }
    }

    // Detect high error rates
    const errorLogs = agentLogs.filter(log => log.level === 'error');
    if (errorLogs.length > agentLogs.length * 0.1) {
      bottlenecks.push({
        id: `bottleneck_${Date.now() + 1}`,
        type: 'external_api',
        severity: 'critical',
        description: `High error rate: ${((errorLogs.length / agentLogs.length) * 100).toFixed(1)}%`,
        detected_at: new Date().toISOString(),
        affected_operations: ['api_calls', 'external_services'],
        impact_score: 95,
        recommendations: [
          'Implement retry mechanisms',
          'Add circuit breakers',
          'Review API integration points'
        ]
      });
    }

    return NextResponse.json({
      success: true,
      bottlenecks_detected: bottlenecks,
      agent_id,
      detection_summary: {
        total_bottlenecks: bottlenecks.length,
        critical_bottlenecks: bottlenecks.filter(b => b.severity === 'critical').length,
        high_priority_bottlenecks: bottlenecks.filter(b => b.severity === 'high').length
      },
      timestamp: new Date().toISOString()
    });

  } catch (error) {
    return NextResponse.json({
      success: false,
      error: error instanceof Error ? error instanceof Error ? error.message : String(error) : 'Unknown error',
      message: 'Failed to detect bottlenecks'
    }, { status: 500 });
  }
}

/**
 * Monitor system resources
 */
async function monitorResources(monitoringConfig: any) {
  try {
    const { duration_minutes = 5, sample_interval_seconds = 10 } = monitoringConfig;
    
    const monitoringId = `monitor_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    const samples: any[] = [];

    // Take immediate sample
    const currentMemory = process.memoryUsage();
    samples.push({
      timestamp: new Date().toISOString(),
      memory: {
        heap_used_mb: currentMemory.heapUsed / 1024 / 1024,
        heap_total_mb: currentMemory.heapTotal / 1024 / 1024,
        external_mb: currentMemory.external / 1024 / 1024
      },
      cpu_usage_percent: Math.random() * 100, // Simulated
      network_io: {
        bytes_per_second: Math.floor(Math.random() * 1000000),
        requests_per_second: Math.floor(Math.random() * 100)
      }
    });

    return NextResponse.json({
      success: true,
      monitoring_started: true,
      monitoring_id: monitoringId,
      _config: {
        duration_minutes,
        sample_interval_seconds,
        estimated_samples: Math.floor((duration_minutes * 60) / sample_interval_seconds)
      },
      initial_sample: (samples && samples[0] ? samples[0] : ""),
      timestamp: new Date().toISOString()
    });

  } catch (error) {
    return NextResponse.json({
      success: false,
      error: error instanceof Error ? error instanceof Error ? error.message : String(error) : 'Unknown error',
      message: 'Failed to start resource monitoring'
    }, { status: 500 });
  }
}

// Helper functions for performance analysis

async function detectPerformanceBottlenecks(profile: PerformanceProfile): Promise<Bottleneck[]> {
  const bottlenecks: Bottleneck[] = [];
  
  // Analyze memory snapshots for leaks
  if (profile.data.memory_snapshots.length > 2) {
    const first = profile.data.memory_snapshots[0];
    const last = profile.data.memory_snapshots[profile.data.memory_snapshots.length - 1];
    const memoryGrowth = first && last ? last.heap_used_mb - first.heap_used_mb : 0;
    
    if (memoryGrowth > 50) { // More than 50MB growth
      bottlenecks.push({
        id: `memory_leak_${Date.now()}`,
        type: 'memory',
        severity: 'high',
        description: `Memory leak detected: ${memoryGrowth.toFixed(2)}MB growth during profiling`,
        detected_at: new Date().toISOString(),
        affected_operations: ['memory_allocation'],
        impact_score: 80,
        recommendations: ['Check for memory leaks', 'Optimize object lifecycle', 'Add garbage collection']
      });
    }
  }

  return bottlenecks;
}

function calculateOverallPerformanceScore(metrics: any): number {
  let score = 100;
  
  // Deduct points for high response times
  if (metrics.avg_response_time_ms > 2000) score -= 20;
  else if (metrics.avg_response_time_ms > 1000) score -= 10;
  
  // Deduct points for high error rates
  if (metrics.error_rate_percent > 10) score -= 30;
  else if (metrics.error_rate_percent > 5) score -= 15;
  
  // Deduct points for low efficiency
  if (metrics.memory_efficiency_score < 70) score -= 15;
  if (metrics.cpu_efficiency_score < 70) score -= 15;
  
  return Math.max(0, score);
}

function generatePerformanceRecommendations(metrics: any): PerformanceRecommendation[] {
  const recommendations: PerformanceRecommendation[] = [];
  
  if (metrics.avg_response_time_ms > 1000) {
    recommendations.push({
      id: `rec_${Date.now()}_1`,
      category: 'performance',
      priority: 'high',
      title: 'Optimize Response Times',
      description: 'Average response time is above acceptable threshold',
      impact_estimate: `Potential ${((2000 - metrics.avg_response_time_ms) / 2000 * 100).toFixed(0)}% improvement`,
      implementation_effort: 'medium',
      code_examples: [
        'Add caching for frequently accessed data',
        'Optimize database queries',
        'Implement connection pooling'
      ]
    });
  }
  
  if (metrics.error_rate_percent > 5) {
    recommendations.push({
      id: `rec_${Date.now()}_2`,
      category: 'error_handling',
      priority: 'critical',
      title: 'Reduce Error Rate',
      description: 'Error rate is above acceptable threshold',
      impact_estimate: 'Improved reliability and user experience',
      implementation_effort: 'high',
      code_examples: [
        'Implement retry mechanisms',
        'Add proper error handling',
        'Improve input validation'
      ]
    });
  }
  
  return recommendations;
}

async function detectAgentBottlenecks(_agentId: string, logs: any[]): Promise<Bottleneck[]> {
  const bottlenecks: Bottleneck[] = [];
  
  // Analyze logs for bottlenecks
  const slowOperations = logs.filter(log => (log.details as any)?.duration > 5000);
  if (slowOperations.length > 0) {
    bottlenecks.push({
      id: `slow_ops_${Date.now()}`,
      type: 'cpu',
      severity: 'medium',
      description: `${slowOperations.length} operations took longer than 5 seconds`,
      detected_at: new Date().toISOString(),
      affected_operations: slowOperations.map(op => op.message).slice(0, 3),
      impact_score: 70,
      recommendations: ['Optimize slow operations', 'Add performance monitoring']
    });
  }
  
  return bottlenecks;
}

function calculateAverageResponseTime(logs: any[]): number {
  const durations = logs.map(log => (log.details as any)?.duration).filter(d => d !== undefined);
  return durations.length > 0 ? durations.reduce((sum, d) => sum + d, 0) / durations.length : 0;
}

function calculateAgentHealthScore(logs: any[]): number {
  if (logs.length === 0) return 0;
  
  const errorCount = logs.filter(log => log.level === 'error').length;
  const errorRate = errorCount / logs.length;
  const baseScore = 100;
  
  return Math.max(0, baseScore - (errorRate * 100));
}